[{"content":"Since a customer requested to change networks of Ceph first in 2023 and then two more times, I felt like I had to put it in writing some time.\nThis use-case should be rare. But here the network design changed multiple times — maybe this is that Agile I heard so much about. But in all seriousness, network design should come first and not be subject to constant change (unless you want to hire me).\nWhen checking the Ceph documentation, I was pleasantly surprised! I made my fair share of negative experiences with Ceph Docs (web and cli help) but this part improved quite a bit for such a niche procedure.\nIn this I will go through the documented ways of how to change the network. I will go through a more thorough example of the process including things not at the core of the change and how to deal with them.\nThere are currently three documented ways to change Network/IPs.\n\u0026ldquo;The Right Way\u0026rdquo; Screenshot from the official Ceph documentation\nWhile old documentation called it \u0026ldquo;The Right Way\u0026rdquo;, it is now called the \u0026ldquo;Preferred Method\u0026rdquo;.\nI wouldn\u0026rsquo;t even call it changing a Ceph Mon\u0026rsquo;s IP since it basically adds a new Ceph Mon with a new IP, wait for the quorum, remove the old Ceph Mon, rinse and repeat.\nThe documentation only suggest to do this in a manual fashion but in practice cephadm and rook should make this trivially easy with changing the service definition to relocate the Ceph Mons, as long as…\n…the new IPs are within the current network or at least reachable.\n\u0026ldquo;The Messy Way\u0026rdquo; While old documentation called it \u0026ldquo;The Messy Way\u0026rdquo;, it is now called \u0026ldquo;Advanced Method\u0026rdquo; — a bit boring, if you ask me since it can get messy, if you are unprepared.\nThe high-level step by step is basically:\nStop the cluster Export the monmap Edit the monmap to remove/add Ceph Mons Inject monmap into Ceph Mons Start Mons, then rest of cluster This leaves out a few things like changing the public_network in the configuration database and how to deal with daemons and all the messiness that might come after.\n\u0026ldquo;The Third Way\u0026rdquo; Okay, I lied. There is no third way but a more detailed version of \u0026ldquo;The Messy Way\u0026rdquo; using cephadm.\nThe high-level steps are the same, but this time done within cephadm shell including the resolution of some of the messiness and it still assumes you know how to get around your setup — if you don\u0026rsquo;t, please abort and ask for help!\nMy Take With My (Customer\u0026rsquo;s) Idiosyncrasies First off, start with a healthy cluster, if you can!\nSecondly, backup monmap, configuration, and keyrings where you can reach it (not /tmp of cephadm shell container or similar).\nMake sure you are prepared and that you communicated the change — duh‽ I will mention some things outside the cluster to look out for at the end.\nI want to prevent data movement of any kind. It is probably not needed but I like the precaution.\nceph osd set noout ceph osd set norebalance ceph osd set nobackfill Stopping all Ceph services using Ansible and prevent them from starting when the hosts will be rebooted for the network changes to be properly applied.\nansible ceph_hosts -m systemd -a \u0026#39;name=ceph.target state=stopped enabled=false\u0026#39; -b On one of the hosts I do more or less what \u0026ldquo;The Third Way\u0026rdquo; says. I change my monmap but with two important changes:\nUsing a volume for the cephadm shell to easily extract monmap Only doing this once and then injecting the same monmap into all Ceph Mons while the documentation suggests repeating the edit process for all Ceph Mons root@ceph01:~# cephadm shell --name mon.ceph01 --mount /root:/roothome Inferring fsid f52ba149-31ea-4da9-9b11-17e745e20d35 Inferring config /var/lib/ceph/f52ba149-31ea-4da9-9b11-17e745e20d35/mon.ceph01/config Using recent ceph image quay.io/ceph/ceph@sha256:1b9158ce28975f95def6a0ad459fa19f1336506074267a4b47c1bd914a00fec0 root@ceph01:/# cd /roothome/ root@ceph01:/roothome# ceph-mon -i ceph01 --extract-monmap monmap-$(date +%F) 2025-11-05T08:56:17.050+0000 70bab6991834 -1 wrote monmap to monmap-2025-11-05 root@ceph01:/roothome# cp monmap-2025-11-05{,-new} This is the time to go to another terminal, and back up the old monmap now! (Maybe even do this a day earlier)\nNow I removed the old IPs and add the new ones. I believe the up-to-date version of the add command more complicated than it needed to be and opted for the old syntax.\nroot@ceph01:/roothome# monmaptool --print monmap-2025-11-05-new monmaptool: monmap file monmap-2025-11-05-new epoch 10 fsid f52ba149-31ea-4da9-9b11-17e745e20d35 last_changed 2024-05-12T12:42:35.759936+0000 created 2022-01-13T13:05:50.128859+0000 min_mon_release 18 (reef) election_strategy: 1 0: [v2:10.10.10.1:3300/0,v1:10.10.10.1:6789/0] mon.ceph01 1: [v2:10.10.10.2:3300/0,v1:10.10.10.2:6789/0] mon.ceph02 2: [v2:10.10.10.3:3300/0,v1:10.10.10.3:6789/0] mon.ceph03 3: [v2:10.10.10.4:3300/0,v1:10.10.10.4:6789/0] mon.ceph04 4: [v2:10.10.10.5:3300/0,v1:10.10.10.5:6789/0] mon.ceph05 root@ceph01:/roothome# monmaptool --rm=ceph{01..05} monmap-2025-11-05-new monmaptool: monmap file monmap-2025-11-05-new monmaptool: removing ceph01 monmaptool: removing ceph02 monmaptool: removing ceph03 monmaptool: removing ceph04 monmaptool: removing ceph05 monmaptool: writing epoch 10 to monmap-2025-11-05-new (0 monitors) root@ceph01:/roothome# monmaptool --add ceph01 192.168.160.1 --add ceph02 192.168.160.2 --add ceph03 192.168.160.3 --add ceph04 192.168.160.4 --add ceph05 192.168.160.5 monmap-2025-11-05-new monmaptool: monmap file monmap-2025-11-05-new monmaptool: writing epoch 10 to monmap-2025-11-05-new (6 monitors) root@ceph01:/roothome# monmaptool --print monmap-2025-11-05-new monmaptool: monmap file monmap-2025-11-05-new epoch 10 fsid f52ba149-31ea-4da9-9b11-17e745e20d35 last_changed 2024-05-12T12:42:35.759936+0000 created 2022-01-13T13:05:50.128859+0000 min_mon_release 18 (reef) election_strategy: 1 0: [v2:192.168.160.1:3300/0,v1:192.168.160.1:6789/0] mon.ceph01 1: [v2:192.168.160.2:3300/0,v1:192.168.160.2:6789/0] mon.ceph02 2: [v2:192.168.160.3:3300/0,v1:192.168.160.3:6789/0] mon.ceph03 3: [v2:192.168.160.4:3300/0,v1:192.168.160.4:6789/0] mon.ceph04 4: [v2:192.168.160.5:3300/0,v1:192.168.160.5:6789/0] mon.ceph05 Ensure this is absolutely correct. When I did this, I accidentally added another Ceph Mon that did not exist. Since there were still enough Ceph Mons to have a quorum, and this change needed to be done during a cluster downtime, I was not worried about temporarily losing quorum. This would also only happen if two more Ceph Mons failed or did not come up right away. I later removed the extra Ceph Mon after the existing Ceph Mons were up again.\nI did not want to do these steps for every Ceph Mon host, so I copied the new monmap to the relevant hosts.\nfor i in {02..05}; do ssh ceph01 sudo cat /root/monmap-2025-11-05-new \\ | ssh ceph$i sudo tee /root/monmap-2025-11-05-new \u0026gt; /dev/null done I ran the following commands to inject the monmap on each one of them, quick and dirty as well.\nfor i in {01..05}; do ssh ceph$i \u0026#34;sudo cephadm shell --mount /root:/roothome --name mon.ceph$i \\ ceph-mon -i ceph$i --inject-monmap /roothome/monmap-2025-11-05-new\u0026#34; done I updated /var/lib/ceph/{FSID}/mon.{MON}/config on every host by replacing the IPs in the config.\nSo far this was only preparations for the network change. In my case the network configuration is managed by an Ansible role, and I already made the necessary changes. This is the point of no return annoying rollback, if one would be needed for any reason.\nNote: For rolling back I would inject the old monmap for all Ceph Mons. After changing the network configuration on the hosts and the switches, this might be harder as I might not be able to easily connect to the hosts to deploy the old network configuration.\nansible-playbook site.yaml -t ceph_networking -D Since I am not in charge of the network hardware, this was the time to talk to the networking people, so they would switch over to the new configuration.\nansible ceph_hosts -m reboot -b After the reboots I checked the network using another Ansible script, that would check for bond failures, negotiated speed, VLAN tags, and finally pinging from every host to every other host on public and cluster network using jumbo frames. Depending on the cluster size this takes a while but is worth the effort in my experience to not run into weird issues due to missing MTU on some interfaces or other configuration errors (hardware or software).\nNote: To ping from everywhere to everywhere it builds a list of IPs filtered by CIDRs and loops over this list on every host.\nansible-playbook check-network.yaml Restart the cluster, if everything is okay.\nansible ceph_hosts -m systemd -a \u0026#39;name=ceph.target state=started enabled=true\u0026#39; -b Setting public_network. I am not sure why it is set on mon and global level, but there is no harm updating both.\nceph config set mon public_network 192.168.160.128/24 ceph config set global public_network 192.168.160.128/24 Fixing Ceph Mgr config:\nceph config generate-minimal-conf \u0026gt;/var/lib/ceph/f52ba149-31ea-4da9-9b11-17e745e20d35/mgr.ceph01.yeinoh/config systemctl reset-failed ceph-f52ba149-31ea-4da9-9b11-17e745e20d35@mgr.ceph01.yeinoh systemctl start $_ Since the orchestrator does not know the new IPs yet, I needed to set them.\nceph orch host set-addr ceph01 192.168.160.1 # repeated for all hosts It will take a few minutes for the orchestrator to gather all information from every host again.\nThe documentation only mentions one last command to reconfigure the Ceph OSDs before it leaves you with the rest to fix for yourself. For example, to get a working standby Ceph Mgr and some other services I ran ceph orch reconfig for all services on this cluster, including Ceph Mons to ensure there is no residue config referencing the old network.\nceph orch reconfig osd ceph orch reconfig mgr ceph orch reconfig mds ceph orch reconfig mon ceph orch reconfig rgw Note: I guess ceph orch redeploy $service would work as well but would take longer.\nNow we unset the flags to allow the cluster to function again normally.\nceph osd unset noout ceph osd unset norebalance ceph osd unset nobackfill Now for the supporting services, that need to be checked for functionality and I will try to include all relevant ones (including unused ones in this case):\nCeph Mgr should provide Ceph Dashboard with proper certificates and Ceph Exporter Observability tooling should be functional: Prometheus, Node-Exporter, Loki, Promtail, Grafana, Alertmanager If you scrape from another external Prometheus you might need to change IPs to be scraped there If there are custom containers, e.g. S3 usage exporter, they should still be reachable Sync services functional: RGW Sync, RBD Mirror, and CephFS Mirror Change DNS RR(set)s for RGWs, etc. Lastly the RADOS clients (RGW, RBD, CephFS) need to be reconfigured to be able to communicate with the cluster again.\nAnd if there are firewalls in place, their rules should be updated beforehand; on hosts (iptables/nftables) and on centralized firewall appliances.\nConclusion While it is possible and fairly straight forward to move a cluster to another or multiple other networks, I would advice avoiding the procedure. You might end up with no cluster at all, if you are not able to fix issues along the way. Even if you do not make mistakes during the process you might still encounter new hurdles with later versions or something might fail during the process.\nUnderstanding how to heal your cluster in an emergency is vital and you should have the ability to do so, if you attempt this.\nThis procedure really should not be a regular occurrence, which is why I did not automate it the first time I had to do it and not the second time either.\n","permalink":"https://www.relg.uk/posts/killing-ceph-by-changing-networks/","summary":"\u003cp\u003eSince a customer requested to change networks of Ceph first in 2023 and then\ntwo more times, I felt like I had to put it in writing some time.\u003c/p\u003e\n\u003cp\u003eThis use-case \u003cem\u003eshould\u003c/em\u003e be rare. But here the network \u003cem\u003edesign\u003c/em\u003e changed multiple\ntimes — maybe this is that \u003cem\u003eAgile\u003c/em\u003e I heard so much about. But in all\nseriousness, network design should come first and not be subject to constant\nchange (unless you want to hire me).\u003c/p\u003e","title":"Killing Ceph by Changing Networks"},{"content":"Apparently I do not have any customers that do not fill their Ceph clusters to the brim. Either because the lack capacity management, do not know their usage (patterns), or do not buy more storage nodes — for one or another reason.\nThis leaves me in the situation to help get the cluster in order.\nDisclaimer This is not a in depth guide for which steps to take exactly but a jumping off point to do your own reading in the Ceph documentation and acting accordingly. When in doubt, reach out to professionals, e.g. on the Mailing List or in IRC.\nObvious Things to Act on Assuming we are not in a critical state yet, where we can no longer use the cluster. A few steps are fairly obvious but worth reiterating:\nUnderstand where data is coming from Stop the ingress of new data Delete unneeded data (also unneeded snapshots) After that you can take a look at how to prevent the cluster filling up in the mid to long term, e.g. retention mechanisms, etc.\nCeph\u0026rsquo;s Balancing Mechanisms If the cluster reports \u0026ldquo;nearfull\u0026rdquo; and \u0026ldquo;backfillfull\u0026rdquo; there is still time and you should check how well balanced your cluster is. Due to how RADOS objects are placed into Placement Groups (PG) using CRUSH PGs can differ — in some cases quite widely — in size. The PGs are being assigned to Ceph OSDs and due to chance you end up with one Ceph OSDs containing multiple large PGs and another Ceph OSD containing only small PGs. In an ideal world every PG and Ceph OSD would have the same size and the distribution would even and would grow even. But, alas, PG sizes vary (especially between pools), Ceph OSDs have different sizes and the storage usage is unevenly distributed. To fight this, Ceph has the Balancer Module that tries to do its best to optimize a low spread of different usages. Make sure it is enabled and used \u0026ldquo;upmap\u0026rdquo;.\nceph balancer status Another variable that can be tuned automatically by Ceph is PGs per pool. It takes in some variables like pool usage, target size and target ratio to calculate the ideal pg_num count for the pools it is enabled on. I recommend to at least put this on warn for every pool, if you have no reason not to. I did have some issues in the past with it but nonetheless it is worth at least getting some advice from it.\nceph osd pool autoscale-status The autoscaler is a good starting point especially, if you do not know the exact distribution of your data at the beginning. In the past PG count always had to be calculated manually with a target count of approximately (or at least) 100 PGs per OSD. There is PG Calc to do this manually and it is still useful today.\nIdeally you know your target pool sizes or at least ratios and set the values accordingly for each pool and let the autoscaler do the rest. Or you can set the bulk flag for your data pools.\nIt is worth checking the PG distribution yourself with PG Calc and see if you have enough PGs per OSD. If you have only about 50 PGs per OSD increasing the PG count can help achieve better balancing and faster recovery times. The reasons for this are fairly simple: If you have more and smaller PGs the likelihood of one PG getting larger is lower and the chance of multiple large PGs ending up on one OSD is lower as well.\nLooking at ceph osd df, and ceph balancer eval can give you an idea how well your data is distributed.\nFixing \u0026ldquo;Wrong\u0026rdquo; Defaults There is one gotcha when doing manual PG calculations and comparing them to what the autoscaler wants to do. While the autoscaler aims for 100 PGs per Ceph OSD by default, it also errs on the side of caution and keeps PG counts usually to low.\nWhile there are downsides to higher PG count (cpu, memory), most modern, non-tiny clusters should aim for a 100 to 200 PG per Ceph OSD. The official documentation recommends to set mon_target_pg_per_osd \u0026ldquo;for all but the very smallest deployments\u0026rdquo; to 200. It does not specify what constitutes \u0026ldquo;very smallest\u0026rdquo; but I would say, if you have more than 50 Ceph OSDs you are not longer operating a \u0026ldquo;very small\u0026rdquo; deployment but a \u0026ldquo;quite small\u0026rdquo; deployment.\nFrom the same passage of the documentation we get: \u0026ldquo;A value above 500 may result in excessive peering traffic and RAM usage.\u0026rdquo;. To prevent this from happening we can limit mon_max_pg_per_osd to 500, 400, or 300 — what ever you are most comfortable with.\nceph config set global mon_target_pg_per_osd 200 ceph config set global mon_max_pg_per_osd 500 Note: The examples below still had these settings at their default. :(\nIf you ask me, the values from the documentation should be the default with the advice to lower these values. Though looking at public telemetry data — maybe not.\nExample of Increasing PG Counts This is from a purely replicated RADOS cluster with HDDs OSDs only (except for the RocksDB).\nBefore:\n❯ ceph balancer eval current cluster score 0.041072 (lower is better) ❯ # awk filters relevant information: min/max OSD, total, PG/OSD, and variance ❯ ceph osd df |awk -v min=100 -v max=0 \\ \u0026#39;/VAR/ {print} /hdd/ { if($17\u0026lt;min){min_line=$0;min=$17}; if($17\u0026gt;max) {max_line=$0;max=$17} } /TOTAL/ { print min_line; print max_line; print \u0026#34;Total:\u0026#34;, sum, \u0026#34;TiB\u0026#34;; print \u0026#34;PG/OSD:\u0026#34;, pg/c }\u0026#39; ID CLASS WEIGHT REWEIGHT SIZE RAW USE DATA OMAP META AVAIL %USE VAR PGS STATUS 129 hdd 9.27039 1.00000 9.3 TiB 4.2 TiB 4.0 TiB 4.6 MiB 8.8 GiB 5.1 TiB 45.30 0.73 48 up 62 hdd 9.27039 1.00000 9.3 TiB 7.4 TiB 7.2 TiB 6.3 MiB 18 GiB 1.9 TiB 79.65 1.29 64 up Total: 1374.5 TiB PG/OSD: 57.8458 MIN/MAX VAR: 0.73/1.29 STDDEV: 6.47 All pools have been set to ceph osd pool set \u0026lt;pool-name\u0026gt; pg_autoscale_mode warn and some of them have been assigned the bulk flag (ceph osd pool set \u0026lt;pool-name\u0026gt; bulk true) to make the autoscaler expect more data in this pool (usually your RBD pool, RGW data pool, or CephFS data pool).\nAfter:\n❯ ceph balancer eval current cluster score 0.025255 (lower is better) ❯ # awk filters relevant information: min/max OSD, total, PG/OSD, and variance ❯ ceph osd df |awk -v min=100 -v max=0 \\ \u0026#39;/VAR/ {print} /hdd/ { sum+=$7; c+=1; pg+=$19; if($17\u0026lt;min){min_line=$0;min=$17}; if($17\u0026gt;max) {max_line=$0;max=$17} } /TOTAL/ { print min_line; print max_line; print \u0026#34;Total:\u0026#34;, sum, \u0026#34;TiB\u0026#34;; print \u0026#34;PG/OSD:\u0026#34;, pg/c }\u0026#39; ID CLASS WEIGHT REWEIGHT SIZE RAW USE DATA OMAP META AVAIL %USE VAR PGS STATUS 56 hdd 9.27039 1.00000 9.3 TiB 4.9 TiB 4.7 TiB 1.2 MiB 10 GiB 4.4 TiB 52.47 0.86 76 up 170 hdd 9.27039 1.00000 9.3 TiB 6.5 TiB 6.3 TiB 1.1 MiB 13 GiB 2.8 TiB 70.20 1.16 98 up Total: 1351.3 TiB PG/OSD: 86.6458 MIN/MAX VAR: 0.86/1.16 STDDEV: 3.42 After increasing pg_num for two pools and waiting for the process to finish (took about half a week), you can see that even though the total size did decreased a little bit (~20TiB) the variance shown by ceph balancer eval and the standard deviation shown by ceph osd df went down. This is also reflected by the fullest OSD being significantly lower (79% -\u0026gt; 70%) and the least filled OSD being better utilised (45% -\u0026gt; 52%).\nNote that you should also let the balancer do its job after increasing the PG count; so this could even improve a little bit.\nYou can see with more PGs the spread of OSD capacities narrows and focuses more on a lower number which is exactly what you want to see. Interestingly, if you look at the PGs per OSD you can also see that after the initial increase in the count of PGs the distribution of PGs decreases its spread as well. This is due to the balancer now getting the chance after the data splits to optimize their placements.\nSlight warning: Do not be alarmed if you get warning about (deep-)scrubs not being done on time. Since increasing PG count leads to lots of backfilling potentially over a prolonged period, Ceph prioritizes backfilling over scrubs. After the cluster is back to a static number of PGs and finished all backfilling task the number of scrubs not done on time should decrease (I would expect it to take about as long as the PG increase or less).\nTo improve recovery speed I set ceph config set osd osd_mclock_profile high_recovery_ops. To not impact daily usage too much, I set up an ad-hoc systemd-timers:\nsystemd-run --on-calendar \u0026#39;Mon..Fri 2024-12-* 18:00\u0026#39; \\ ceph config set osd osd_mclock_profile high_recovery_ops systemd-run --on-calendar \u0026#39;Mon..Fri 2024-12-* 08:00\u0026#39; \\ ceph config set osd osd_mclock_profile high_client_ops systemd-run --on-calendar \u0026#39;2025-01-01 08:00\u0026#39; \\ ceph config set osd osd_mclock_profile high_client_ops Note: Keep in mind, that if the server these commands were run on restarts, the timers are gone. So make sure to check that you have indeed set the proper osd_mclock_profile after you are done. You could also remove the setting to go back to the balance default with ceph config rm osd osd_mclock_profile\nGetting Your Hands Dirty If this is still not enough there is more you can do, by adjusting the Ceph OSD (re)weights.\nThe existing scripts only looked at the current utilization and acted upon this information. Then you had to wait for the result and tweak another value. I wrote a few scripts for looking at changes during backfilling and adjusting based on future balance results.\nI created a repo, if you want to check them out.\nEmergency Only If you are really in a pickle and need to get a blocked cluster running again to be able to rebalance (not to use it!), you can change what is recognized as a backfillfull or full Ceph OSD. I do not recommend this!\nceph osd dump | grep ratio ceph osd set-backfillfull-ratio $higher ceph osd set-full-ratio $more_higher Also, make sure to change it back after your incident!\nceph osd set-backfillfull-ratio .9 ceph osd set-full-ratio .95 ceph osd dump | grep ratio ","permalink":"https://www.relg.uk/posts/killing-ceph-by-filling-it/","summary":"\u003cp\u003eApparently I do not have any customers that do not fill their Ceph clusters to\nthe brim. Either because the lack capacity management, do not know their usage\n(patterns), or do not buy more storage nodes — for one or another reason.\u003c/p\u003e\n\u003cp\u003eThis leaves me in the situation to help get the cluster in order.\u003c/p\u003e\n\u003ch2 id=\"disclaimer\"\u003eDisclaimer\u003c/h2\u003e\n\u003cp\u003eThis is not a in depth guide for which steps to take exactly but a jumping off\npoint to do your own reading in the Ceph documentation and acting accordingly.\nWhen in doubt, reach out to professionals, e.g. on the Mailing List or in IRC.\u003c/p\u003e","title":"Killing Ceph by Filling It"},{"content":"It is time again for me to renew my GPG keys and I wanted to write something about GnuPG/GPG and YubiKey for a while now. I want to go over some things I think someone should know, if they want to use GPG and a YubiKey for GPG. If I think there are good resource for learning about certain aspects, I will link to them.\nWhat this is not This does not explain basics of cryptography. I assume you know about asymmetric and symmetric encryption, and signing (basically reverse asymmetric encryption of the contents hash). It also is not a guide on how to use GPG on a normal day. You probably already know how to that. Take a look at signing your git commits and using it for SSH authentication! This does not recommend any hardware. This does not take a look at signing git commits with SSH (though that is a interesting topic imo). This does not go over installation of GPG or tooling around using a smartcard (e.g. pcscd and pcsc_scan, ykman, kdf-setup, etc.) — maybe later. This also does not go over thread modeling. You need to know if an intelligence service is after you, if data corruption is a risk, etc. Be Serious If you are serious about using GPG, you should understand more than just how to give your key to an application to use it to sign/(de)crypt for you. I would recommend you never set the expiration of more than one year. Get comfortable with generating and renewing GPG keys. Never create a non-expiring key; this is because in case you loose access to the secret key (e.g. forgetting the password), the key will still be invalidated eventually.\nI would also recommend understanding more about the anatomy and though behind the workings of GPG. I really liked Neal Walfield\u0026rsquo;s Advanced Intro to GnuPG.\nPlayground If you just run a GPG command like gpg -K you usually use your ~/.gnupg/ (on Linux). To use another, temporary, and clean configuration directory you can set GNUPGHOME. You can export it like in the following or provide the --homedir argument for every call to GPG.\nexport GNUPGHOME=$(mktemp -d -t gnupg_$(date +%Y%m%d%H%M)_XXX) Actions of Keys You might guess that there are at least two actions a key can be used for: signing (a message) and encrypting a message.\nBut GPG defines two more actions: certifying and authentication\nYou can have separate keys for all four actions or you can combine sign, certify (signing keys), and authenticate (signing for SSH authentication). Signing and certifying are often combined, but I prefer to have a dedicated primary/certify key, to be able to move it off my devices. This is called \u0026ldquo;offline\u0026rdquo;; more on that later.\n# generating primary key, valid for 1 year, this could also be 2006-01-02 # use a secure passphrase gpg --quick-gen-key your@email.example ed25519 cert 1y # generate sub key for signing and encryption (requires primary passphrase) gpg --quick-add-key 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A ed25519 sign 1y gpg --quick-add-key 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A cv25519 encr 1y You can not now take a look a your key. The normal way or with more details:\n❯ gpg -K your@email.example sec ed25519 2025-01-05 [C] [expires: 2026-01-05] 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A uid [ultimate] your@email.example ssb ed25519 2025-01-05 [S] [expires: 2026-01-05] ssb cv25519 2025-01-05 [E] [expires: 2026-01-05] There are a few things to talk about. The new key only has one uid, you can however add more, for multiple email addresses. This also shows that you trust this key ultimate-ly. Only trust your own keys to that level. But more to that later.\nThe sec shows the private primary key, ssb the private subkey.\n❯ gpg -k your@email.example pub ed25519 2025-01-05 [C] [expires: 2026-01-05] 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A uid [ultimate] your@email.example sub ed25519 2025-01-05 [S] [expires: 2026-01-05] sub cv25519 2025-01-05 [E] [expires: 2026-01-05] For this key and for imported public keys you can also see pub for the primary key and sub for the public subkey.\n❯ gpg --keyid-format 0xlong -K --with-subkey-fingerprint --with-keygrip your@email.example sec ed25519/0x50ED5BF8E4042B5A 2025-01-05 [C] [expires: 2026-01-05] 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A Keygrip = 2BFDFFC57B771DCE7F009C3BEF37142EBCF4B8E5 uid [ultimate] your@email.example ssb ed25519/0xB654F428066CB8A3 2025-01-05 [S] [expires: 2026-01-05] 149A02287C20580A7CF01CAAB654F428066CB8A3 Keygrip = 82887047B2E87C91CC4EA9915D22A6C4D5B23006 ssb cv25519/0x587AE7468688C837 2025-01-05 [E] [expires: 2026-01-05] 3782DF5CA1038377F172D881587AE7468688C837 Keygrip = A57B578C56165F6EFFBC1249DDE4E69F0553D433 When using your GPG key you usually reference the primary key and GPG selects the most recent subkey to do the actual work. If you have only one sub key of a kind, there cannot be any confusion, but if you have multiple subkeys you can also reference a specific subkey with SUBKEYFINGERPRINT!.\nAlso note that the 0xlong format uses the ending of the full keyid, not the start. The long version is often what you see when referring to keys.\nThe keygrip is what you will see on the file system. In ${GNUPGHOME:-$HOME/.gnupg}/private-keys-v1.d/ you can find ${keygrip}.key.\nList Packets GPG was designed to process messages in one pass and not require loading the entire messages into memory. It works on streams of packages in a specific order. This means, if you want decrypt something, the information about which key needs to be used comes first.\nMessage Looking at a simple message (a new line), encrypting it to our newly created key, and then inspecting its packets.\n❯ echo |gpg -aer 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A |gpg --list-packets gpg: encrypted with cv25519 key, ID 587AE7468688C837, created 2025-01-05 \u0026#34;your@email.example\u0026#34; # off=0 ctb=84 tag=1 hlen=2 plen=94 :pubkey enc packet: version 3, algo 18, keyid 587AE7468688C837 data: [263 bits] data: [392 bits] # off=96 ctb=d4 tag=20 hlen=2 plen=70 new-ctb :aead encrypted packet: cipher=9 aead=2 cb=16 length: 70 # off=117 ctb=a3 tag=8 hlen=1 plen=0 indeterminate :compressed packet: algo=2 # off=119 ctb=cb tag=11 hlen=2 plen=7 new-ctb :literal data packet: mode b (62), created 1736115332, name=\u0026#34;\u0026#34;, raw data: 1 bytes The first two lines are printed to stderr and show information about the encrypted message. Then there follow four packets.\nThe first one is information about the public key used — note that the keyid is not the primary key but the id of the subkey for encryption. The second one is a asymmetrically encrypted packet containing the symmetric session key to decrypt the message. If you \u0026ldquo;asymmetrically\u0026rdquo; encrypt a message to multiple recipients, all it does is encrypt the symmetric key multipel times. This way the message does not have to be duplicated.\nThere is debate about if you should use AEAD due to a split between GnuPG and the OpenPGP specification it is based on. TL;DR: disable it for now. Side note: Should you ever be forced to to decrypt data encrypted to you, you should never give up your entire secret key, but only decrypt relevant session keys. This way your key is not compromised. The third packets contains the fourth packet, as far as I know. I am not an expert on GPG but as far as I understood it, there is a hierarchy to packets, but I could not find an easy way to show that. The fourth packet is the actual encrypted data that can be decrypted with the decrypted symmetric key from earlier. Note: Also try the command from above with -vv.\nNow try the same with echo | gpg -s | gpg --list-packets. You will three packets: onepass_sig, literal data, and signature.\nThe onepass_sig packet is useful for checking the signature in one pass. This way the hash for for the signature can be calculated while the message is already in memory.\nKey You can do the same on public and secret keys.\n❯ gpg --export your@email.example -a |gpg --list-packets # off=0 ctb=98 tag=6 hlen=2 plen=51 :public key packet: version 4, algo 22, created 1736114781, expires 0 pkey[0]: [80 bits] ed25519 (1.3.6.1.4.1.11591.15.1) pkey[1]: [263 bits] keyid: 50ED5BF8E4042B5A # off=53 ctb=b4 tag=13 hlen=2 plen=18 :user ID packet: \u0026#34;your@email.example\u0026#34; # off=73 ctb=88 tag=2 hlen=2 plen=153 :signature packet: algo 22, keyid 50ED5BF8E4042B5A version 4, created 1736114781, md5len 0, sigclass 0x13 digest algo 10, begin of digest 13 2e hashed subpkt 33 len 21 (issuer fpr v4 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A) hashed subpkt 2 len 4 (sig created 2025-01-05) hashed subpkt 27 len 1 (key flags: 01) hashed subpkt 9 len 4 (key expires after 1y0d0h0m) hashed subpkt 11 len 4 (pref-sym-algos: 9 8 7 2) hashed subpkt 34 len 1 (pref-aead-algos: 2) hashed subpkt 21 len 5 (pref-hash-algos: 10 9 8 11 2) hashed subpkt 22 len 3 (pref-zip-algos: 2 3 1) hashed subpkt 30 len 1 (features: 07) hashed subpkt 23 len 1 (keyserver preferences: 80) subpkt 16 len 8 (issuer key ID 50ED5BF8E4042B5A) data: [254 bits] data: [256 bits] # off=228 ctb=b8 tag=14 hlen=2 plen=51 :public sub key packet: version 4, algo 22, created 1736114906, expires 0 pkey[0]: [80 bits] ed25519 (1.3.6.1.4.1.11591.15.1) pkey[1]: [263 bits] keyid: B654F428066CB8A3 # off=281 ctb=88 tag=2 hlen=2 plen=245 :signature packet: algo 22, keyid 50ED5BF8E4042B5A version 4, created 1736114906, md5len 0, sigclass 0x18 digest algo 10, begin of digest 50 5d hashed subpkt 33 len 21 (issuer fpr v4 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A) hashed subpkt 2 len 4 (sig created 2025-01-05) hashed subpkt 27 len 1 (key flags: 02) hashed subpkt 9 len 4 (key expires after 1y0d0h0m) subpkt 16 len 8 (issuer key ID 50ED5BF8E4042B5A) subpkt 32 len 117 (signature: v4, class 0x19, algo 22, digest algo 10) data: [256 bits] data: [255 bits] # off=528 ctb=b8 tag=14 hlen=2 plen=56 :public sub key packet: version 4, algo 18, created 1736114910, expires 0 pkey[0]: [88 bits] cv25519 (1.3.6.1.4.1.3029.1.5.1) pkey[1]: [263 bits] pkey[2]: [32 bits] keyid: 587AE7468688C837 # off=586 ctb=88 tag=2 hlen=2 plen=126 :signature packet: algo 22, keyid 50ED5BF8E4042B5A version 4, created 1736114910, md5len 0, sigclass 0x18 digest algo 10, begin of digest 73 9c hashed subpkt 33 len 21 (issuer fpr v4 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A) hashed subpkt 2 len 4 (sig created 2025-01-05) hashed subpkt 27 len 1 (key flags: 0C) hashed subpkt 9 len 4 (key expires after 1y0d0h0m) subpkt 16 len 8 (issuer key ID 50ED5BF8E4042B5A) data: [256 bits] data: [256 bits] The first packet is the public or secret key (depending on what you looked at). You might spot expires 0. This means no expiration but will be overwritten later. The second packet is the user id. The third packet is probably the most interesting packet as it is the signature of the two earlier packets and contains the settings for the key, like preferred algorithms and the expiration. This is the reason why you can easily change the expiration on a key without invalidating the key or invalidating signatures of the key and uid: The key stays the same, only the signature changes. Every uid get its own signature, so it can be easily removed. Then the two subkeys follow, first the public/secret key itself,… …then the signature from the primary key that also tells others that these are subkeys of the primary key and other settings. This means, that to change expiration of the subkeys, you need the primary key. These keys are not special to the primary key. In fact, it is possible to reuse the same same subkeys and recertify them to another primary key (should you have lost the old one). There is also other black magic you can do. Signing keys also cross-sign the primary key to prevent someone pretending that the subkey is theirs. Offline Keys and a YubiKey Generally offline key only means, that it is currently not on the device. It could be on another computer, on a flash drive, or a smart card like a YubiKey. It is generally recommended to use an offline primary key, but any key could be offline.\nHaving an offline primary key comes with some caveats. While you can use all other keys normally, you cannot create, revoke, sign other keys, or change subkeys or uids. This includes settings, e.g. expiration.\nIt is important to understand that a smartcard or a YubiKey with smartcard functionality a key only goes one way. You can store a key on a smartcard/YK but you can never retrieve it (in lieu of exploits). This is very much intentional, as the idea of smartcards is to do the secure computing on the card and never load any secrets into comptuer memory. This is by design how it is supposed to work.\nThis is why you need to watch out for the command addtocard which saves the key to the smartcard and deletes the key from disk. Meaning you can never backup that key again, if you do not have a backup already. The same applies if you generate the key on the smartcard — your computer will never see the contents of that key.\nAnother limitation of my YubiKey is, that it only has three key slots. One for a signature key, one for an encryption key, one for an authentication key. So if you use separate keys for certify and sign, you are SOL because you can only put one into the signing slot. In my case I put the primary key into the signature slot as an additional backup and to be able to manage subkeys more easily without needing to go to the true offline primary key.\nIf you see sec#, the primary key is not on the device. If you see sec\u0026gt; the primary key is on a smartcard (if you look at the keygrip file you will find a stub instead of the actual key).\nBackup and Removal of Key There is something more important than backing up your encrypted email — backing up your secret keys. The easiest way is to just backup the entire GNUPGHOME, usually ~/.gnupg/. In my case I have LUKS encrypted flash drive I copy it to. All usual backup practices apply — 3-2-1, in case your house gets struck by lightning while the flash drive is inserted into your computer.\nDATE=$(date +%F) mkdir /run/media/syphdias/LUKS001/gpg/.gnupg-$DATE rsync -aP ~/.gnupg/ /run/media/syphdias/LUKS001/gpg/.gnupg-$DATE I use the date, in case I mess something up, during renewal. Now we remove the primary key from our keyring on the device. We already found the keygrip when looking at our keys.\n❯ rm ~/.gnupg/private-keys-v1.d/2BFDFFC57B771DCE7F009C3BEF37142EBCF4B8E5.key ❯ GNUPGHOME=gnupg_202501051540_gqK/ gpg -K /home/syphdias/.gnupg/pubring.kbx -------------------------------------------------------------------------------- sec# ed25519 2025-01-05 [C] [expires: 2026-01-05] 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A uid [ultimate] your@email.example ssb ed25519 2025-01-05 [S] [expires: 2026-01-05] ssb cv25519 2025-01-05 [E] [expires: 2026-01-05] Seeing sec# shows the successful removal of the primary key. Keep in mind the caveats from above.\nRenewing with Offline Key A year has passed and you are still into GPG for some nerdish reason and want to keep working with out keys without regenerating completely new ones.\n❯ cd /run/media/syphdias/LUKS001/gpg/ ❯ cp -r .gnupg-2024-01-10/ .gnupg-2025-01-14/ ❯ # only work on a copy of your backup for safety ❯ gpg --quick-set-expire usage: gpg [options] --quick-set-exipre FINGERPRINT EXPIRE [SUBKEY-FPRS] ❯ # renew primary key ❯ GNUPGHOME=.gnupg-2025-01-14 gpg --quick-set-expire 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A 2027-01-05 ❯ # renew subkeys ❯ GNUPGHOME=.gnupg-2025-01-14 gpg --quick-set-expire 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A 2027-01-05 149A02287C20580A7CF01CAAB654F428066CB8A3 3782DF5CA1038377F172D881587AE7468688C837 You can use GNUPGHOME=.gnupg-2025-01-14 gpg -K this worked. If you wanted you could also change other attributes at this time, like preferred algorithms, or add another uid. If we are happy with the keyring, you can keep the directory as backup to copy for next year.\nThere are a few ways how you could get the renewed offline keys to your machine(s) now. You could copy the subkeys by keygrip — dont! Or copy over the entire keyring and remove the primary key again — meh! The proper way is to export the secret subkeys only and import them into your current keyring.\n❯ # check if you will import what you wanted ❯ GNUPGHOME=.gnupg-2025-01-14 gpg --export-secret-subkeys --export-options export-minimal 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A |gpg --import --import-options show-only ❯ GNUPGHOME=.gnupg-2025-01-14 gpg --export-secret-subkeys --export-options export-minimal 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A |gpg --import ❯ # if you published your GPG key, update the published key ❯ gpg --send-keys 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A You could only export certain subkeys, if you wanted. Or, if you have multiple uids, you could also filter your export with --export-filter keep-ui=mbox=your@email.example. To check your export you can check the import without importing by using the command gpg --import --import-opstions show-only. This can also be useful for others\u0026rsquo; public keys.\nEvery time you change settings of your GPG key, you create a new signature. With --export-optitons export-minimal removes all signatures except the most recent one.\nMoving Key to YubiKey If you want to have your primary key not just in your backup, you can edit your key (gpg --edit-key KEY) and select keytocard. Leave with save. From then on you can use the key on the YubiKey. Keep in mind that there are only three key slots. I mainly have this a additional backup of my primary key and to be able to use the primary key to manage subkeys that I might not need in my backup and to set settings on-the-fly without requiring my true offline primary key.\nPublishing to a Keyserver Keyservers were very open in the past. You just uploaded your key to them and there were forever findable and others could upload their signatures for other keys, etc. This is kinda dead. For one you could DOS someone with overwhelming their key with signature. This was basically the last nail in the coffin for the Web of Trust. Another reason the traditional keyservers are no longer around is the GDPR which requires the option to remove personal identifiable data on request. Today you can either publish your GPG in a place you think proper for people to manually find it, use Web Key Directory (WKD) to store keys on your website at /.well-known/openpgpkey/hu/hash-of-uid, or upload your key to https://keys.openpgp.org where you will also need to verify your email address.\nMisc In the past GPG wanted key owners verifying each other\u0026rsquo;s keys and establish a \u0026ldquo;Web of Trust\u0026rdquo; in key signing parties. This did not take hold and is basically nerd sports for enthusiasts that do it for the fun of it. The practical application is basically dead. Trust on first use (TOFU) is easier in practice with less overhead. You can combine the two modes by setting trust-model tofu+pgp in your ${GNUPGHOME:-$HOME/.gnupg}/gpg.conf.\nYubiKeys has more uses than acting as a smartcard for GPG.\n❯ ykman --device 12345678 info WARNING: PC/SC not available. Smart card (CCID) protocols will not function. ERROR: Unable to list devices for connection Device type: YubiKey 5C NFC Serial number: 12345678 Firmware version: 5.4.3 Form factor: Keychain (USB-C) Enabled USB interfaces: OTP, FIDO, CCID NFC transport is enabled Applications USB NFC Yubico OTP Enabled Enabled FIDO U2F Enabled Enabled FIDO2 Enabled Enabled OATH Enabled Enabled PIV Enabled Enabled OpenPGP Enabled Enabled YubiHSM Auth Enabled Enabled Settings There are a few settings I think you should take a look at in the ~/.gnupg/gpg.conf file.\n# If you do not set this option the first secret key found will be used default-key YOURKEYID # If you encrypt someone, you will never again be able to decrypt it. This can # be a feature to be anonymous, but can be a pain, if you use this to send # emails and still want to be able to read your sent emails. default-recipient-self # disable comments in clear text signatures and ASCII armored messages no-comments # default to long format keyid-format 0xlong # try GPG agent before asking for passphrase use-agent # use TOFU and WOT/PGP trust-model tofu+pgp # used for --(recv|send|search)-keys keyserver hkps://keys.openpgp.org:443/ I will not include any cipher preferences as they will go out of date.\nBest-ish Practices …as far as I can tell.\nuse secure passphrases reference key by long format (opposed to short id or email) again, always set expiration for all keys create revoke file for your primary key gpg --gen-revoke KEY do not use comment field maybe use name field — peoples opinions vary Further Reading There is probably more that I want to write but at some point it just has to be another day, another post.\nI can recommend drduh\u0026rsquo;s YubiKey-Guide. If you want to use a YubiKey at least give it a skim. And if you got your YubiKey, read it whole.\n","permalink":"https://www.relg.uk/posts/gpg-and-offline-keys/","summary":"\u003cp\u003eIt is time again for me to renew my GPG keys and I wanted to write something\nabout GnuPG/GPG and YubiKey for a while now. I want to go over some things I\nthink someone should know, if they want to use GPG and a YubiKey for GPG. If I\nthink there are good resource for learning about certain aspects, I will link to\nthem.\u003c/p\u003e\n\u003ch2 id=\"what-this-is-not\"\u003eWhat this is not\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eThis does not explain basics of cryptography. I assume you know about\nasymmetric and symmetric encryption, and signing (basically \u003ca href=\"https://blog.koehntopp.info/2018/03/04/hashes-in-structures.html\"\u003ereverse\nasymmetric encryption of the contents hash\u003c/a\u003e). It also is not a guide on how to\nuse GPG on a normal day. You probably already know how to that. Take a look at\nsigning your git commits and using it for SSH authentication!\u003c/li\u003e\n\u003cli\u003eThis does not recommend any hardware.\u003c/li\u003e\n\u003cli\u003eThis does not take a look at signing git commits with SSH (though that is a\ninteresting topic imo).\u003c/li\u003e\n\u003cli\u003eThis does not go over installation of GPG or tooling around using a smartcard\n(e.g. \u003ccode\u003epcscd\u003c/code\u003e and \u003ccode\u003epcsc_scan\u003c/code\u003e, \u003ccode\u003eykman\u003c/code\u003e, \u003ccode\u003ekdf-setup\u003c/code\u003e, etc.) — maybe later.\u003c/li\u003e\n\u003cli\u003eThis also does not go over thread modeling. You need to know if an\nintelligence service is after you, if data corruption is a risk, etc.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"be-serious\"\u003eBe Serious\u003c/h2\u003e\n\u003cp\u003eIf you are serious about using GPG, you should understand more than just how to\ngive your key to an application to use it to sign/(de)crypt for you. I would\nrecommend you never set the expiration of more than one year. Get comfortable\nwith generating and renewing GPG keys. \u003cem\u003eNever\u003c/em\u003e create a non-expiring key; this\nis because in case you loose access to the secret key (e.g. forgetting the\npassword), the key will still be invalidated eventually.\u003cbr\u003e\nI would also recommend understanding more about the anatomy and though behind\nthe workings of GPG. I really liked Neal Walfield\u0026rsquo;s \u003ca href=\"https://begriffs.com/posts/2016-11-05-advanced-intro-gnupg.html\"\u003eAdvanced Intro to GnuPG\u003c/a\u003e.\u003c/p\u003e","title":"GPG and Offline Keys"},{"content":"If I had to guess, why people use an Arch-based system, I would guess a big reason would be the AUR — even though it is not officially supported. It is a big part of the community and the appeal of Arch. This is a story how the AUR can break some things and the reason it is not officially supported.\nIt all started with a normal update. In my case I used the AUR helper paru to update all system packages and all AUR packages. Only obs-studio-tytan652 failed when trying to compile, but I rarely use OBS Studio (it will get fixed, eventually).\nBroken Electron-based Applications When I tried to launch my note taking app Obsidian, it never started. I dropped into a shell and tried again.\n❯ obsidian /usr/lib/electron25/electron: error while loading shared libraries: libdav1d.so.6: cannot open shared object file: No such file or directory I had seem behavior like this before after an update. When you update your kernel and you are still running the old kernel. If the running (old) kernel needs to load a new module it expects the old libraries but cannot find them as only the new ones are available.\nIt is generally also a bad idea to symlink libraries. If you would symlink the old library to the location of the old one, there is no guarantee that they are even remotely compatible.\nTip 1: Don\u0026rsquo;t break your system with symlinking shared libraries.\nFor the new-kernel-old-module problem a reboot usually suffices. However, electron apps would probably not use any kernel shared libraries. To make sure anyways, I did reboot.\nTip 2: Reboot after a upgrade if libraries cannot be found.\nAfter the reboot I was still not able to launch Obsidian or any other Electron-based app.\nElectron is a framework for building desktop applications. It uses the Chromium browser engine and Node.js to make it easy to build cross-platform applications — especially, if you are already familiar with building web apps.\nWhat is Actually Missing and Where Should it Come From? Since the issue seems to come from [electon] and not Obsidian itself I looked at electron directly which yielded the same error.\nWhen looking for library dependencies for the command electron, there are two red herrings. One is, that the package electron is only a meta package to link to the latest stable version of electron The second red herring is that /usr/bin/electron25 is a shell script to exec /usr/lib/electron25/electron. So to check for the shared library dependencies, we can follow the trail like this:\n❯ which electron /usr/bin/electron ❯ ls -l /usr/bin/electron lrwxrwxrwx 1 root root 10 Jun 16 08:50 /usr/bin/electron -\u0026gt; electron25 ❯ file /usr/bin/electron25 /usr/bin/electron25: Bourne-Again shell script, ASCII text executable ❯ cat /usr/bin/electron25 #!/usr/bin/bash […snip…] name=electron25 […snip…] exec /usr/lib/${name}/electron \u0026#34;${flags[@]}\u0026#34; \u0026#34;$@\u0026#34; ❯ file /usr/lib/electron25/electron /usr/lib/electron25/electron: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 4.4.0, BuildID[sha1]=adabc98fbf2c1422ad6b6c4de371150f4fe605aa, stripped Tip 3: Find the binary that is actually run.\nTo find the libraries you can run ldd and filtered for the library name.\n❯ ldd /usr/lib/electron25/electron | grep libdav1d libdav1d.so.7 =\u0026gt; /usr/lib/libdav1d.so.7 (0x00007f41ea424000) ❯ ls -l /usr/lib/libdav1d.so.7 lrwxrwxrwx 1 root root 17 Oct 4 17:21 /usr/lib/libdav1d.so.7 -\u0026gt; libdav1d.so.7.0.0 ❯ pacman -F /usr/lib/libdav1d.so.7 usr/lib/libdav1d.so.7 is owned by extra/dav1d 1.3.0-1 Let\u0026rsquo;s walk through this. The binary wants libdav1d.so.7 and it can be found in /usr/lib/. The way this resolution from filename to path works is similar to how the PATH variable works. If you want to learn more about where libraries live, search for LS_LIBRARY_PATH and ld. For now, it is enough to know that the library is present at a know location, and points to another (existing) file.\nBut actually this library is not the one the error complains about. In the error above it complained about libdav1d.so.6 being absent.\nI reached out to the Arch Linux Mailing List which was very helpful. With the help of lddtree (from the package pax-utils) I could look recursively at the required libraries. Again, I filtered for the relevant library name but show 5 lines above the matches to see potential parent dependencies.\n❯ lddtree /usr/lib/electron25/electron | grep -B5 libdav1d libavcodec.so.60 =\u0026gt; /usr/lib/libavcodec.so.60 libswresample.so.4 =\u0026gt; /usr/lib/libswresample.so.4 libsoxr.so.0 =\u0026gt; /usr/lib/libsoxr.so.0 libgomp.so.1 =\u0026gt; /usr/lib/libgomp.so.1 libvpx.so.8 =\u0026gt; /usr/lib/libvpx.so.8 libdav1d.so.6 =\u0026gt; None -- libva-x11.so.2 =\u0026gt; /usr/lib/libva-x11.so.2 libX11-xcb.so.1 =\u0026gt; /usr/lib/libX11-xcb.so.1 libxcb-dri3.so.0 =\u0026gt; /usr/lib/libxcb-dri3.so.0 libvdpau.so.1 =\u0026gt; /usr/lib/libvdpau.so.1 libOpenCL.so.1 =\u0026gt; /usr/lib/libOpenCL.so.1 libdav1d.so.7 =\u0026gt; /usr/lib/libdav1d.so.7 This still shows libdav1d.so.7 at the root level of the dependencies but also libdav1d.so.6 as dependency of libavcodec.so.60. It cannot resolve the name to a library location so None gets displayed.\nSo where is this library from?\n❯ pacman -F libavcodec.so.60 extra/ffmpeg 2:6.0-12 usr/lib/libavcodec.so.60 ❯ pacman -Qi ffmpeg |grep -e Name -e Prov -e Requi Name : ffmpeg-obs Provides : ffmpeg=6.0.r12.ga6dc929 libavcodec.so=60-64 libavdevice.so=60-64 libavfilter.so=9-64 libavformat.so=60-64 libavutil.so=58-64 libpostproc.so=57-64 libswresample.so=4-64 libswscale.so=7-64 Required By : chromaprint chromium electron25 ferdium-bin firefox gst-libav krita obs-studio-tytan652 opencv peek qt5-webengine telegram-desktop thunderbird vlc-luajit Hm, do you notice something?\nTip 4: You can use ldd, lddtree (pax-utils) to find shared library dependencies that a binary need (is linked against).\nTip 5: You can use pacman -F to find the package for file and pacman -Qi to show information about a package, like actual name or which other packages require it.\nThe Culprit The library is provided by ffmpeg a widely used library for decoding of all kinds of media. But the installed version is not the regular version from the official arch (extra) repositories but ffmpeg-obs, a version from the AUR which is required by obs-studio-tytan652.\nSo why is it broken? Every time a library is updated, every program that uses it, needs to also be rebuilt to link against the latest version. If you are running only official packages from Arch Linux they take good care that if one library gets an update every program or library using it (recursively) will be updated as well to reflect the changed version. This is the reason why a partially upgraded system is unsupported. They cannot guarantee that the libraries match up.\nThe AUR on the other hand is independent from the official package repositories. If something changes in the official repos, the AUR package maintainer need to notice and react to it. If it is a binary package, they need to rebuild it themselves. If it is a package built from source it needs to be rebuilt on the users machine as well as soon as the new libraries are available (can also be done through a version increment, e.g. increase the suffix to -2).\nAt this point I had two options.\nRemove obs-studio-tytan652 and switch back to extra/ffmpeg (the officially) supported version Rebuilt ffmpeg-obs to link against the latest version of dav1d. When I realised what had happened there was already a new version of ffmpeg-obs. But I will keep this in mind for future updates.\nConclusion If this error had happened in an AUR package I would have known that I probably had to rebuild it to link to the new dependencies. In this case however, one package in the dependency chain was replaced by an unofficial one. Which made it less obvious to track down the issue.\nTip 6: Be weary what packages you replace with packages from the AUR.\n","permalink":"https://www.relg.uk/posts/they-say-dont-use-the-aur/","summary":"\u003cp\u003eIf I had to guess, why people use an Arch-based system, I would guess a big\nreason would be the AUR — even though it is not officially supported. It is a\nbig part of the community and the appeal of Arch. This is a story how the AUR\ncan break some things and the reason it is not officially supported.\u003c/p\u003e\n\u003cp\u003eIt all started with a normal update. In my case I used the AUR helper \u003ca href=\"https://github.com/Morganamilo/paru\"\u003e\u003ccode\u003eparu\u003c/code\u003e\u003c/a\u003e\nto update all system packages and all AUR packages. Only \u003ccode\u003eobs-studio-tytan652\u003c/code\u003e\nfailed when trying to compile, but I rarely use OBS Studio (it will get fixed,\neventually).\u003c/p\u003e","title":"They Say Don't Use the AUR"},{"content":"I recently was looking for a way to run a systemd service on the last business day of the month, but I could only find an answer for first business day of every month on Stack Overflow which was wrong. So I looked into it.\nSpoiler: This is not possible with one calendar expression.\nIf you remember only one thing from this blog post, remember systemd-analyse. There are quite a few useful subcommands, e.g. verify. You should check them out, if you do not know them yet with systemd-analyse -h.\nFor timers, we want systemd-analyse calendar.\nFirst Business Day of the Month To achieve this we can set OnCalendar twice in the timer unit, we do not need two timer units:\n[Timer] OnCalendar=Mon..Fri *-*-01 OnCalendar=Mon *-*-02..03 Mon..Fri *-*-01 will activate if the first day of the month is a business day Mon *-*-02..03 will activate if the second or third day of the month is a Monday. This happens if the first was a Sunday, or if the first was a Saturday and the second was a Sunday. There is no overlap. To verify this is true we can use (--iterations is optional but very useful):\nsystemd-analyze calendar \u0026#39;Mon..Fri *-*-01\u0026#39; \u0026#39;Mon *-*-02..03\u0026#39; --iterations 10 The output is a bit unwieldy since it treats both expressions separately and prints three versions of the iterations.\nsystemd-analyze calendar \u0026#39;Mon..Fri *-*-01\u0026#39; \u0026#39;Mon *-*-02..03\u0026#39; --iterations 10 \\ |grep Iteration |sort -k4 This works for a English locale but it will filter out the first iteration because it is listed as \u0026ldquo;Next elapse\u0026rdquo;. The get a good overview in this case it suffices.\nLast Business Day of the Month Last day is very similar to first day, but requires dates that were introduced in systemd v233. Again, we need two expressions:\n[Timer] OnCalendar=Mon..Fri *-*~01 OnCalendar=Fri *-*~02..03 Mon..Fri *-*~01 triggers if the last day of the month is a business day Fri *-*~02..03 triggers if the second to last or third to last day of the month was a Friday. This happens if the weekend is on the last day of the month. Verifying this works just the same:\nsystemd-analyze calendar \u0026#39;Mon..Fri *-*~01\u0026#39; \u0026#39;Fri *-*~02..03\u0026#39; --iterations 10 Optionally, filter and sort with the caveats from above:\nsystemd-analyze calendar \u0026#39;Mon..Fri *-*~01\u0026#39; \u0026#39;Fri *-*~02..03\u0026#39; --iterations 10 \\ |grep Iteration |sort -k4 ","permalink":"https://www.relg.uk/posts/first-and-last-business-day-of-the-month-with-systemd-timers/","summary":"\u003cp\u003eI recently was looking for a way to run a systemd service on the last business\nday of the month, but I could only find an answer for first business day of\nevery month on Stack Overflow which was wrong. So I looked into it.\u003c/p\u003e\n\u003cp\u003eSpoiler: This is not possible with one calendar expression.\u003c/p\u003e\n\u003cp\u003eIf you remember only one thing from this blog post, \u003cstrong\u003eremember\n\u003ccode\u003esystemd-analyse\u003c/code\u003e\u003c/strong\u003e. There are quite a few useful subcommands, e.g. \u003ccode\u003everify\u003c/code\u003e.\nYou should check them out, if you do not know them yet with \u003ccode\u003esystemd-analyse -h\u003c/code\u003e.\u003c/p\u003e","title":"First and Last Business Day of the Month With Systemd Timers"},{"content":"I recently was consulted on a Ceph Cluster running into nearfull and backfillfull for the first time. One Ceph OSD was utilized over 85% and another over 90%. The operators were unaware of the meaning and what to do about it, so took a look.\nLooking at ceph status and ceph df, I noticed something. Try to spot it yourself – I made it easier by removing some stuff around it:\n$ ceph status [...] health: HEALTH_WARN 1 pools have many more objects per pg than average 1 backfillfull osd(s) 1 nearfull osd(s) Low space hindering backfill (add storage if this doesn\u0026#39;t resolve itself): 1 pg backfill_toofull 1 pgs not deep-scrubbed in time 1 pgs not scrubbed in time 20 pool(s) backfillfull services: [...] osd: 96 osds: 96 up (since 4w), 96 in (since 12M); 1 remapped pgs [...] data: volumes: 4/4 healthy pools: 20 pools, 4769 pgs objects: 31.90M objects, 117 TiB usage: 351 TiB used, 522 TiB / 873 TiB avail pgs: 299136/95689743 objects misplaced (0.313%) 4763 active+clean 5 active+clean+scrubbing+deep 1 active+remapped+backfill_toofull [...] # ceph df --- RAW STORAGE --- CLASS SIZE AVAIL USED RAW USED %RAW USED hdd 873 TiB 522 TiB 351 TiB 351 TiB 40.19 TOTAL 873 TiB 522 TiB 351 TiB 351 TiB 40.19 --- POOLS --- POOL ID PGS STORED OBJECTS USED %USED MAX AVAIL device_health_metrics 1 4096 907 MiB 108 2.7 GiB 0 14 TiB rbd 4 145 97 TiB 25.39M 290 TiB 87.43 14 TiB [...] The raw usage was only at 40%. Why would one disk contain so much data? The balancer was in upmap mode and active. But even with no balancer, this kind of miss-balancing would be extreme and very unlikely.\nYou may have already spotted something odd in the Ceph Pool configuration. While device_health_metrics contained less than 1GiB, it had 4096 PGs. At the same time rbd contained 97TiB in just 145 PGs.\n145 is not just no power of two (which would usually produce a Ceph Warning), but also way to low for the about of data and Ceph OSD count.\nWhat Does This Mean for Storage Distribution? Estimating the size of one PG for pool rbd yields about 685GiB (97TiB/145). How many (average sized) PGs will lead to utilization of one disk over 85%?\nAbout 11.4 (85% * 9TiB / 685GiB)\nUnfortunately, not every PG is the same size. Looking at the sizes, multiple PG exceed 800GiB. Furthermore not every Ceph OSD receives the same amount of PGs. And as we will soon see the number of PGs was trying to get lower.\nCause and Distributing Data But what actually caused the bogus PG numbers? The answer is: The PG Autoscaler. For some reason only device_health_metrics set a target_size_ratio to 0.1. This lead to the effective ratio to be 1 for this pool. Apparently the autoscaling assumed this would mean all data would be stored in this pool. This also explained why the number of PGs was not a power of two. The autoscaler set target_pg_num to 32 to reduce the pool rbd even more. This was why there was not Ceph Warning. This also means that if there were no disks were running full right now, it certainly would have happened in the following days.\nBefore removing the ratio, I wanted to know what would happen. I disabled autoscaling (ceph osd pool set noautoscale) and removed the target ratio:\n# ceph osd pool set device_health_metrics target_size_ratio 0 # ceph osd pool autoscale-status POOL SIZE TARGET SIZE RATE RAW CAPACITY RATIO TARGET RATIO EFFECTIVE RATIO BIAS PG_NUM NEW PG_NUM AUTOSCALE BULK device_health_metrics 906.5M 3.0 873.1T 0.0000 1.0 4096 1 on False rbd 99048G 3.0 873.1T 0.3323 1.0 32 1024 on False [...] This was a lot better and we decided to re-enable autoscaling (ceph osd pool unset noautoscale) right away.\nAfter a few minutes the backfillfull was gone. Soon to be followed by the nearfull. After a few days of rebalancing both pools had the proper PG count.\nI am not sure why the ratio was set and why it was interpreted as it was. The docs suggest this would not be a problem and I could not reproduce the behavior in a more recent version of Ceph. So this was potentially fixed already.\n","permalink":"https://www.relg.uk/posts/killing-your-ceph-with-autoscaling/","summary":"\u003cp\u003eI recently was consulted on a Ceph Cluster running into nearfull and backfillfull\nfor the first time. One Ceph OSD was utilized over 85% and another over 90%. The\noperators were unaware of the meaning and what to do about it, so took a look.\u003c/p\u003e\n\u003cp\u003eLooking at \u003ccode\u003eceph status\u003c/code\u003e and \u003ccode\u003eceph df\u003c/code\u003e, I noticed something. Try to spot it\nyourself – I made it easier by removing some stuff around it:\u003c/p\u003e","title":"Killing your Ceph with Autoscaling"},{"content":"I recently revived my Synology D415+ NAS from silicon death and it looks like it works fine again. When I bought it, I wanted to be able to run any docker image. Which is why I opted for Atom instead of ARM. Which is also why I upgraded RAM to 8GB. The disks basically never spun down which made it quite noisy. Now, I just want it to be silent, if not in use.\nI initially thought I could replace the DiskStation Manager (DSM) with a proper Linux but from what I gathered, it is \u0026ldquo;not doable without deeper knowledge\u0026rdquo;.\nAdjusting Fans I only inserted the first SSD so far and installed DSM 7.0 on it. The only audible sound was the fans spinning and I found a guide to use a custom fan profile to turn them off completely for low loads.\nStep one: Set \u0026ldquo;Fan Speed Mode\u0026rdquo; to \u0026ldquo;Quiet mode\u0026rdquo; via the GUI in \u0026ldquo;Hardware \u0026amp; Power\u0026rdquo;. This can also be done by setting\nStep two: Turning off fan check to allow for 0 speed operations.\n# cat /usr/local/etc/rc.d/fan_check_disable.sh \u0026lt;\u0026lt;EOF #!/bin/sh echo 0 \u0026gt; /sys/module/avoton_synobios/parameters/check_fan EOF # chmod 755 /usr/local/etc/rc.d/fan_check_disable.sh Step three: Backup /usr/syno/etc.defaults/scemd.xml and usr/syno/etc/scemd.xml Step four: Adjust fan profile as described in the guide with some modifications in /usr/syno/etc.defaults/scemd.xml and usr/syno/etc/scemd.xml.\n--- /usr/syno/etc/scemd.xml_2022-04-23\t2021-10-18 15:26:05.000000000 +0200 +++ /usr/syno/etc/scemd.xml\t2022-04-23 01:12:07.740595553 +0200 @@ -14,17 +14,21 @@ \u0026lt;cpu_temperature fan_speed=\u0026#34;99%40hz\u0026#34; action=\u0026#34;SHUTDOWN\u0026#34;\u0026gt;95\u0026lt;/cpu_temperature\u0026gt; \u0026lt;/fan_config\u0026gt; \u0026lt;fan_config period=\u0026#34;20\u0026#34; threshold=\u0026#34;6\u0026#34; type=\u0026#34;DUAL_MODE_LOW\u0026#34; hibernation_speed=\u0026#34;UNKNOWN\u0026#34;\u0026gt; -\t\u0026lt;disk_temperature fan_speed=\u0026#34;21%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;0\u0026lt;/disk_temperature\u0026gt; -\t\u0026lt;disk_temperature fan_speed=\u0026#34;35%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;42\u0026lt;/disk_temperature\u0026gt; -\t\u0026lt;disk_temperature fan_speed=\u0026#34;50%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;46\u0026lt;/disk_temperature\u0026gt; -\t\u0026lt;disk_temperature fan_speed=\u0026#34;70%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;53\u0026lt;/disk_temperature\u0026gt; +\t\u0026lt;disk_temperature fan_speed=\u0026#34;01%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;0\u0026lt;/disk_temperature\u0026gt; +\t\u0026lt;disk_temperature fan_speed=\u0026#34;10%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;41\u0026lt;/disk_temperature\u0026gt; +\t\u0026lt;disk_temperature fan_speed=\u0026#34;20%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;46\u0026lt;/disk_temperature\u0026gt; +\t\u0026lt;disk_temperature fan_speed=\u0026#34;35%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;48\u0026lt;/disk_temperature\u0026gt; +\t\u0026lt;disk_temperature fan_speed=\u0026#34;50%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;50\u0026lt;/disk_temperature\u0026gt; +\t\u0026lt;disk_temperature fan_speed=\u0026#34;70%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;54\u0026lt;/disk_temperature\u0026gt; \u0026lt;disk_temperature fan_speed=\u0026#34;99%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;58\u0026lt;/disk_temperature\u0026gt; \u0026lt;disk_temperature fan_speed=\u0026#34;99%40hz\u0026#34; action=\u0026#34;SHUTDOWN\u0026#34;\u0026gt;61\u0026lt;/disk_temperature\u0026gt; -\t\u0026lt;cpu_temperature fan_speed=\u0026#34;21%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;0\u0026lt;/cpu_temperature\u0026gt; -\t\u0026lt;cpu_temperature fan_speed=\u0026#34;50%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;50\u0026lt;/cpu_temperature\u0026gt; -\t\u0026lt;cpu_temperature fan_speed=\u0026#34;99%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;85\u0026lt;/cpu_temperature\u0026gt; -\t\u0026lt;cpu_temperature fan_speed=\u0026#34;99%40hz\u0026#34; action=\u0026#34;SHUTDOWN\u0026#34;\u0026gt;95\u0026lt;/cpu_temperature\u0026gt; +\t\u0026lt;cpu_temperature fan_speed=\u0026#34;01%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;0\u0026lt;/cpu_temperature\u0026gt; +\t\u0026lt;cpu_temperature fan_speed=\u0026#34;10%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;57\u0026lt;/cpu_temperature\u0026gt; +\t\u0026lt;cpu_temperature fan_speed=\u0026#34;20%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;62\u0026lt;/cpu_temperature\u0026gt; +\t\u0026lt;cpu_temperature fan_speed=\u0026#34;50%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;65\u0026lt;/cpu_temperature\u0026gt; +\t\u0026lt;cpu_temperature fan_speed=\u0026#34;99%40hz\u0026#34; action=\u0026#34;NONE\u0026#34;\u0026gt;80\u0026lt;/cpu_temperature\u0026gt; +\t\u0026lt;cpu_temperature fan_speed=\u0026#34;99%40hz\u0026#34; action=\u0026#34;SHUTDOWN\u0026#34;\u0026gt;90\u0026lt;/cpu_temperature\u0026gt; \u0026lt;/fan_config\u0026gt; \u0026lt;fan_config hw_version=\u0026#34;Synology-DX5\u0026#34; period=\u0026#34;20\u0026#34; threshold=\u0026#34;6\u0026#34; type=\u0026#34;DUAL_MODE_HIGH_EBOX\u0026#34; hibernation_speed=\u0026#34;FULL\u0026#34;\u0026gt; Step five: Reboot NAS\nAdding Disks If you checked out the source for the fan profile, you might have noticed that I skipped something more obvious. The IronWolf drives I bought are really loud when spun up – louder than the stock fan configuration in fact. For quiet operation they need to spin down when idle.\nLooking at the md configuration I noticed something odd.\n# cat /proc/mdstat Personalities : [raid1] md2 : active raid1 sda3[0] 239376512 blocks super 1.2 [1/1] [U] md1 : active raid1 sda2[0] 2097088 blocks [4/1] [U___] md0 : active raid1 sda1[0] 2490176 blocks [4/1] [U___] unused devices: \u0026lt;none\u0026gt; The first SSD (sda) I inserted was split into 3 partitions and turned into 3 arrays. md2 was the main bulk and what will is volume1. It is not mounted directly to /volume1 tough, but through /dev/mapper/cachedev_0. I assume this is to enable adding a caching device later (which makes no sense in this case) to be more flexible.\n# df -h /volume1/ Filesystem Size Used Avail Use% Mounted on /dev/mapper/cachedev_0 220G 92G 101G 48% /volume1 # ls -l /dev/mapper/cachedev_0 /dev/md2 brw------- 1 root root 253, 0 Apr 23 11:58 /dev/mapper/cachedev_0 brw------- 1 root root 9, 2 Apr 23 11:58 /dev/md2 # dmsetup ls --tree # ^^^^^^ notice major and minor device numbers match up cachedev_0 (253:0) └─ (9:2) md0(sda1) is used for / while I could not exactly figure out what md1(sda2) was used for – I read it was swap somewhere but I could not verify that, so don\u0026rsquo;t quote me on that.\n# df -h / Filesystem Size Used Avail Use% Mounted on /dev/md0 2.3G 1.2G 1.1G 52% / Notice [U___] on both md0 and md1 and what happens after I insert a second SSD and configure it as Storage Pool 2 (no volume) via the GUI.\n# cat /proc/mdstat Personalities : [raid1] md3 : active raid1 sdb3[0] 120212800 blocks super 1.2 [1/1] [U] md2 : active raid1 sda3[0] 239376512 blocks super 1.2 [1/1] [U] md1 : active raid1 sdb2[4] sda2[0] 2097088 blocks [4/1] [U___] [=======\u0026gt;.............] recovery = 37.0% (776576/2097088) finish=0.5min speed=36979K/sec md0 : active raid1 sdb1[4] sda1[0] 2490176 blocks [4/1] [U___] [=====\u0026gt;...............] recovery = 28.7% (716928/2490176) finish=0.9min speed=32587K/sec unused devices: \u0026lt;none\u0026gt; # cat /proc/mdstat Personalities : [raid1] md3 : active raid1 sdb3[0] 120212800 blocks super 1.2 [1/1] [U] md2 : active raid1 sda3[0] 239376512 blocks super 1.2 [1/1] [U] md1 : active raid1 sdb2[1] sda2[0] 2097088 blocks [4/2] [UU__] md0 : active raid1 sdb1[1] sda1[0] 2490176 blocks [4/2] [UU__] unused devices: \u0026lt;none\u0026gt; Initializing the new disk resulted in it being split into three partitions as well. It added the first two partitions to the RAID1 arrays md0 and md1 and left the third partition for usage. This is kind of clever. After the initial array sync – took a few seconds –, I could now remove the first SSD, if I wanted without losing my operating system. I would still lose everything I installed on the volume from this disk though. Indeed, this happens to every disk I insert and initialize a storage pool on.\nI inserted my 2 10T HDDs now, and indeed they undergo the same procedure. The array sync took about 1-2 minutes this time and I ended up with md4 and 2 more members for md0 and md1.\n# cat /proc/mdstat Personalities : [raid1] md4 : active raid1 sdd3[1] sdc3[0] 9761614848 blocks super 1.2 [2/2] [UU] [...] md1 : active raid1 sdd2[3] sdc2[2] sdb2[1] sda2[0] 2097088 blocks [4/4] [UUUU] md0 : active raid1 sdd1[3] sdc1[2] sdb1[1] sda1[0] 2490176 blocks [4/4] [UUUU] [...] This is great for simplicity and redundancy. I can yank any 3 disks and my system keeps running. But what if anything is read or written to the system disk? I expect this to hinder hibernation and spin down quite a bit.\nDebugging HDD Hibernation Part 1 I found the tool /usr/syno/sbin/syno_hibernation_debug to analyse hibernation fails (1 for \u0026ldquo;Cannot Enter Hibernation\u0026rdquo; or 2 for \u0026ldquo;Which Interrupt Hibernation\u0026rdquo;). The older one used in many forum posts was and no longer available (syno_hibernate_debug_tool --enable 1)\nI enabled the debug log by setting some options in /etc/synoinfo.conf\nenable_hibernation_debug=\u0026#34;yes\u0026#34; hibernation_debug_level=\u0026#34;1\u0026#34; I tailed /var/log/hibernationFull.log to get a feel what happens. I stopped the tail after I realised that reading a file from the disk I want to see idle might not work very well.\nAfter about 600 seconds the disks spun down only to spin up again 30 seconds later. I looked at the hibernation log to see what had happened.\n[Sat Apr 23 15:42:15 2022] ppid:1(systemd), pid:22779(syno_hibernatio), dirtied inode 20738 (hibernation.log) on md0 [Sat Apr 23 15:42:15 2022] ppid:1(systemd), pid:22779(syno_hibernatio), dirtied inode 20738 (hibernation.log) on md0 [Sat Apr 23 15:42:15 2022] ppid:1(systemd), pid:22779(syno_hibernatio), dirtied inode 20738 (hibernation.log) on md0 [Sat Apr 23 15:42:15 2022] ppid:1(systemd), pid:22779(syno_hibernatio), dirtied inode 30536 (hibernationFull.log) on md0 [Sat Apr 23 15:42:15 2022] ppid:1(systemd), pid:22779(syno_hibernatio), dirtied inode 30536 (hibernationFull.log) on md0 [Sat Apr 23 15:42:15 2022] ppid:1(systemd), pid:22779(syno_hibernatio), dirtied inode 30536 (hibernationFull.log) on md0 Huh, that\u0026rsquo;s the pid for the /usr/syno/sbin/syno_hibernation_debug process. Did it wake itself up?\nI looked deeper into to syno_hibernation_debug script to find out what was going on. The script mainly took care of a few things:\nReading configuration and running itself in the background if enable_hibernation_debug=\u0026quot;yes\u0026quot; was found and hibernation_debug_level was 1 or 2. If not, it killed the running debug process echo 1 \u0026gt; /proc/sys/vm/block_dump if enabled and echo 0 \u0026gt; /proc/sys/vm/block_dump if not it loops over /sys/block/sd{a..d}/device/syno_idle_time (in my case) to see if the idle time was below the configured standby time then it looks at dmesg | tail -500 it also writes to two log files (this should be find, it calls sync instantly afterwards and sleeps for 20s) This is when I gave up on the script. There really is nothing too special about it that I cannot do by hand without waking the disks up by myself. But I still have the feeling that internals might be at play that will always sync the array at some point in time. I don\u0026rsquo;t want the system to be on HDDs.\nI tried again, this time by hand.\necho 1 \u0026gt; /proc/sys/vm/block_dump while sleep 1s; do cat /sys/block/sd{a..d}/device/syno_idle_time; echo; done This time is was something else.\n[Sat Apr 23 16:41:17 2022] ppid:1(systemd), pid:14381(scemd), dirtied inode 30475 (disk_overview.xml) on md0 [Sat Apr 23 16:41:17 2022] ppid:1(systemd), pid:14381(scemd), dirtied inode 30475 (disk_overview.xml) on md0 I wonder, if I missed this the first time, but dmesg does not go back far enough and I am not willing to spend the time again. The other reason is that I will definitely do something about the HDDs in the array. Simply ssh-ing to the NAS wakes it up – reading authorized_keys or something? Probably more, logging, etc.?\nRemoving HDDs from Array The fact that the idle times if all four disks (2xSSD, 2xHDD) were almost always in sync to the same value, makes me sure that with this configuration it will be very hard to achieve total silence with spin down or even debug it properly.\nI removed the HDD partitions form arrays md0 and md1.\nmdadm /dev/md0 --fail /dev/sdc1 mdadm /dev/md0 --remove /dev/sdc1 mdadm /dev/md0 --fail /dev/sdd1 mdadm /dev/md0 --remove /dev/sdd1 mdadm /dev/md1 --fail /dev/sdc2 mdadm /dev/md1 --remove /dev/sdc2 mdadm /dev/md1 --fail /dev/sdd2 mdadm /dev/md1 --remove /dev/sdd2 Resulting in this (notice that I ):\n# cat /proc/mdstat Personalities : [raid1] md4 : active raid1 sdd3[1] sdc3[0] 9761614848 blocks super 1.2 [2/2] [UU] [...] md1 : active raid1 sdb2[1] sda2[0] 2097088 blocks [4/2] [UU__] md0 : active raid1 sdb1[1] sda1[0] 2490176 blocks [4/2] [UU__] [...] Synology did not like that. Important: Do not shrink the arrays. I did so at first (mdadm /dev/md0 --grow -n 2, same for md1) but when I later rebooted the machine, it went to the setup wizard instead. Fixing this was easy: I shut down the NAS, removed the HDDs and booted again. After it was done, I inserted the HDDs again, and assembled the array again (can be done via GUI).\nAdvice: Do not do this – unless you are sure of the consequences it might have. I expect this to break with OS upgrades and the like. Same for fan profiles.\nI looked at idle times again and was pleased to see that ssh-ing to the machine only reset idle times for the remaining SSDs in the system arrays.\nSadly that did not last long since the idle time rose above 10 minutes without the disks spinning down. Did Synology stop tracking the disk for some reason?\nTime to postpone for this day.\nDebugging HDD Hibernation Part 2 I noticed when the HDD did spin down, looking at /sys/block/sd{a..d}/device/syno_idle_time took longer. So this does not count as something to interrupt the idle time but it does wake up the disk. The syno_hibernation_debug script basically only works for checking why a disk does not enter hibernation but not for what wakes it up, because it will wake the disk up itself. All debugging efforts basically lead to spin-up – the German wiki page on hibernation even touches on something like this briefly.\nNew approach: I disabled all debugging measures (including hibernation log), closed all ssh connections, closed the webinterface and check for open connections to the machine (lsof -i@$hostname_of_NAS). Time for some series, a 10-15 minute timer and listening if the disks spin down at some point. I left echo 1 \u0026gt; /proc/sys/vm/block_dump to check for what woke up the drives if they did.\nWith Advanced Sleep After waiting about ten minutes the disks spun down and the yellow LEDs went off (Status and disks) while the blue power LED stayed solid. The fans did not spin up. (There was some network activity I saw on my router at a later date, mainly ARP and NTP).\nWhen I connected to the web GUI after over an hour the disks spun up and the LED went back on. Looking at dmesg and searching for the HDDs I saw some activity I assume to be a result of waking up from deep sleep and checking if anything changed with the disks.\n[Sun Apr 24 17:15:56 2022] sd 5:0:0:0: [sdd] Write cache: enabled, read cache: enabled, doesn\u0026#39;t support DPO or FUA [Sun Apr 24 17:16:01 2022] sd 4:0:0:0: [sdc] Write cache: disabled, read cache: enabled, doesn\u0026#39;t support DPO or FUA [Sun Apr 24 17:16:02 2022] sd 5:0:0:0: [sdd] Write cache: disabled, read cache: enabled, doesn\u0026#39;t support DPO or FUA [Sun Apr 24 17:16:26 2022] ppid:2(kthreadd), pid:30085(kworker/3:0), READ block 8 on sdd3 (8 sectors) [Sun Apr 24 17:16:26 2022] ppid:2(kthreadd), pid:30085(kworker/3:0), READ block 8 on sdc3 (8 sectors) [Sun Apr 24 17:16:26 2022] ppid:2(kthreadd), pid:6707(md4_raid1), WRITE block 8 on sdd3 (1 sectors) [Sun Apr 24 17:16:26 2022] ppid:2(kthreadd), pid:6707(md4_raid1), WRITE block 8 on sdc3 (1 sectors) [Sun Apr 24 17:16:26 2022] ppid:2(kthreadd), pid:6707(md4_raid1), WRITE block 8 on sdd3 (1 sectors) [Sun Apr 24 17:16:26 2022] ppid:2(kthreadd), pid:6707(md4_raid1), WRITE block 8 on sdc3 (1 sectors) I waited until the disk were silent again and the LEDs went off and connected via ssh – again, disk spin.\n[Sun Apr 24 17:29:55 2022] sd 4:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn\u0026#39;t support DPO or FUA Without Advanced Sleep My hope was, by not going into deep sleep to not wake the HDDs from their spin-down when connecting to the GUI or via ssh. After waiting 10 minutes the disks spun down but all LEDs stayed on. About every 10 minutes the fans spun up for 2-3 minutes but the disks stayed spun down. My guess would be that not going into deeps sleep the CPU and maybe the SSDs needed more power wich lead to higher temperature and thus a higher cooling need.\nWhen I connected via ssh the HDDs spun up. There was nothing for the disks in dmesg what had accessed the disks.\nI waited for the disks to go silent again and tried the same with connecting via the GUI. Unfortunately, the disks ramped up again.\n[Sun Apr 24 18:42:59 2022] ppid:2(kthreadd), pid:30021(kworker/2:1), READ block 8 on sdb3 (8 sectors) [Sun Apr 24 18:42:59 2022] ppid:2(kthreadd), pid:30021(kworker/2:1), READ block 8 on sda3 (8 sectors) Hunting Ghosts This is where I put down my pen for now and talk about what I have learned on this adventure.\nI guess my initial assumption that the disks didn\u0026rsquo;t properly spin down was false. Maybe I had installed something that kept disks awake back then or didn\u0026rsquo;t properly configure hibernate. Either way, do not assume something is (still) broken; verify before you invest time in debugging. For the mathematically inclined, for a complete induction it is essential to prove the base case before doing the induction step.\nMeasuring has its costs or there ain\u0026rsquo;t no such thing as a free lunch. When looking at metrics, surveying the data will change the data from what it would have been – reminds me of the uncertainty principle, somehow.\nWhat\u0026rsquo;s next I will keep my weird RAID configuration (for now), in case it did help. I am comfortable with dealing with potential fails that might occur. I moved the HDDs to the slots away from the mainboard to reduce heat radiating to them. I will keep the advanced/deep sleep configuration since there was no observable benefit from disabling deep sleep, if ssh-ing would wake up the HDDs anyways. I still do not understand this behavior and if anybody has an idea and how to fix it, please let me know.\nPS: I am aware that constantly spinning disks might not wear out as fast but this is a risk I am willing to take right now.\n","permalink":"https://www.relg.uk/posts/silent-synology/","summary":"\u003cp\u003eI recently revived my Synology D415+ NAS from \u003ca href=\"https://www.youtube.com/watch?v=PkZ0249t7SI\u0026amp;t=339s\"\u003esilicon death\u003c/a\u003e and it looks like\nit works fine again. When I bought it, I wanted to be able to run any docker\nimage. Which is why I opted for Atom instead of ARM. Which is also why I upgraded\nRAM to 8GB. The disks basically never spun down which made it quite noisy.\nNow, I just want it to be silent, if not in use.\u003c/p\u003e","title":"Silent Synology"},{"content":"Recently re-inspired to start to blog, I decided to open – same as Jay Faulkner – with a meta post about why, what to expect, and how I (will) do it.\nWhy I Want to Blog If I start to learn a new topic, I feel like a total beginner. But the more I learn about something, the more I can draw from related topics to generate a more complete understanding of how it works. We all go through this. But at which point is it okay to talk about it as if you were knowledgable about the topic? I would say, do it earlier than you think, be honest about your state of understanding, and do not be afraid to be wrong (as long as it does not kill anyone). Writing is understanding.\nWhen you write – or speak – about a topic several things happen. You are forced to form complete sentences and express the idea as clear as you can. While you do, you might discover that you are still missing pieces or that your current understanding is wrong is some way. Another thing you might notice is, that you are unsure, if it is correct. Again, do not be afraid to be wrong but take the opportunity to learn more. Maybe there is another way to look at the concept that might be easier to explain. Writing about topic or concept can be helpful to someone reading it as well as writing about the learning experiences itself. My hope is to write about topics where I am on the way up from the valley of despair (Dunning–Kruger effect) or make the valley not as deep. I currently only write into my personal notes – mainly for documentation and findability. But it is too easy to just jot down bullet points and not actually understanding what you have written. I hope blogging deepens my understanding of things and also helps others understand the topic a little bit better.\nInspiration I read some other tech blogs like Florian Haas, Michael Stapelberg, and Kristian Köhntopp. I hugely respect all of them and enjoy their different content. I also enjoy the content liveoverflow produces on YouTube.\nWhat to Expect There is not set path for what you will find here in the future but I have some rough ideas what topics to cover. Subject to change but stuff I currently thing about:\ndebugging issues and learning experiences git, gnupg, gaming on Linux, i3, restic and systemd, scripts, vim, zsh Obsidian: documentation, note taking maybe opinions: remote work eventually: slides to talks How I Blog Most importantly – since this is something new to me – irregular and opportunistic. If I find something interesting enough, you will find it here.\nOn the technical side: The repo syphdias.github.io contains this page\u0026rsquo;s contents as markdown files and configuration files. GitHub Actions are being used to use hugo with the theme PaperMod to generate a static page on the branch gh-pages. It is then hosted by GitHub Pages.\nThere is a RSS/Atom feed you can use and I might enable comments if I am in the mood.\nIf you find mistakes in any of my posts, feel free to contribute a pull request.\n","permalink":"https://www.relg.uk/posts/starting-to-blog/","summary":"\u003cp\u003eRecently re-inspired to start to blog, I decided to open – same as\n\u003ca href=\"https://jay.jvf.cc/posts/about-itself/\"\u003eJay Faulkner\u003c/a\u003e – with a meta post about why, what to expect, and how I (will) do\nit.\u003c/p\u003e\n\u003ch2 id=\"why-i-want-to-blog\"\u003eWhy I Want to Blog\u003c/h2\u003e\n\u003cp\u003eIf I start to learn a new topic, I feel like a total beginner. But the more I\nlearn about something, the more I can draw from related topics to generate a\nmore complete understanding of how it works. We all go through this. But\nat which point is it okay to talk about it as if you were knowledgable about the\ntopic? I would say, do it earlier than you think, be honest about your state of\nunderstanding, and do not be afraid to be wrong (as long as it does not kill\nanyone). Writing is understanding.\u003c/p\u003e","title":"Starting to Blog"}]