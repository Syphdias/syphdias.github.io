<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>relg.uk</title><link>https://www.relg.uk/</link><description>Recent content on relg.uk</description><generator>Hugo -- 0.140.2</generator><language>en</language><lastBuildDate>Tue, 14 Jan 2025 23:21:30 +0100</lastBuildDate><atom:link href="https://www.relg.uk/index.xml" rel="self" type="application/rss+xml"/><item><title>GPG and Offline Keys</title><link>https://www.relg.uk/posts/gpg-and-offline-keys/</link><pubDate>Tue, 14 Jan 2025 23:21:30 +0100</pubDate><guid>https://www.relg.uk/posts/gpg-and-offline-keys/</guid><description>&lt;p>It is time again for me to renew my GPG keys and I wanted to write something
about GnuPG/GPG and YubiKey for a while now. I want to go over some things I
think someone should know, if they want to use GPG and a YubiKey for GPG. If I
think there are good resource for learning about certain aspects, I will link to
them.&lt;/p>
&lt;h2 id="what-this-is-not">What this is not&lt;/h2>
&lt;ul>
&lt;li>This does not explain basics of cryptography. I assume you know about
asymmetric and symmetric encryption, and signing (basically &lt;a href="https://blog.koehntopp.info/2018/03/04/hashes-in-structures.html">reverse
asymmetric encryption of the contents hash&lt;/a>). It also is not a guide on how to
use GPG on a normal day. You probably already know how to that. Take a look at
signing your git commits and using it for SSH authentication!&lt;/li>
&lt;li>This does not recommend any hardware.&lt;/li>
&lt;li>This does not take a look at signing git commits with SSH (though that is a
interesting topic imo).&lt;/li>
&lt;li>This does not go over installation of GPG or tooling around using a smartcard
(e.g. &lt;code>pcscd&lt;/code> and &lt;code>pcsc_scan&lt;/code>, &lt;code>ykman&lt;/code>, &lt;code>kdf-setup&lt;/code>, etc.) — maybe later.&lt;/li>
&lt;li>This also does not go over thread modeling. You need to know if an
intelligence service is after you, if data corruption is a risk, etc.&lt;/li>
&lt;/ul>
&lt;h2 id="be-serious">Be Serious&lt;/h2>
&lt;p>If you are serious about using GPG, you should understand more than just how to
give your key to an application to use it to sign/(de)crypt for you. I would
recommend you never set the expiration of more than one year. Get comfortable
with generating and renewing GPG keys. &lt;em>Never&lt;/em> create a non-expiring key; this
is because in case you loose access to the secret key (e.g. forgetting the
password), the key will still be invalidated eventually.&lt;br>
I would also recommend understanding more about the anatomy and though behind
the workings of GPG. I really liked Neal Walfield&amp;rsquo;s &lt;a href="https://begriffs.com/posts/2016-11-05-advanced-intro-gnupg.html">Advanced Intro to GnuPG&lt;/a>.&lt;/p></description><content:encoded><![CDATA[<p>It is time again for me to renew my GPG keys and I wanted to write something
about GnuPG/GPG and YubiKey for a while now. I want to go over some things I
think someone should know, if they want to use GPG and a YubiKey for GPG. If I
think there are good resource for learning about certain aspects, I will link to
them.</p>
<h2 id="what-this-is-not">What this is not</h2>
<ul>
<li>This does not explain basics of cryptography. I assume you know about
asymmetric and symmetric encryption, and signing (basically <a href="https://blog.koehntopp.info/2018/03/04/hashes-in-structures.html">reverse
asymmetric encryption of the contents hash</a>). It also is not a guide on how to
use GPG on a normal day. You probably already know how to that. Take a look at
signing your git commits and using it for SSH authentication!</li>
<li>This does not recommend any hardware.</li>
<li>This does not take a look at signing git commits with SSH (though that is a
interesting topic imo).</li>
<li>This does not go over installation of GPG or tooling around using a smartcard
(e.g. <code>pcscd</code> and <code>pcsc_scan</code>, <code>ykman</code>, <code>kdf-setup</code>, etc.) — maybe later.</li>
<li>This also does not go over thread modeling. You need to know if an
intelligence service is after you, if data corruption is a risk, etc.</li>
</ul>
<h2 id="be-serious">Be Serious</h2>
<p>If you are serious about using GPG, you should understand more than just how to
give your key to an application to use it to sign/(de)crypt for you. I would
recommend you never set the expiration of more than one year. Get comfortable
with generating and renewing GPG keys. <em>Never</em> create a non-expiring key; this
is because in case you loose access to the secret key (e.g. forgetting the
password), the key will still be invalidated eventually.<br>
I would also recommend understanding more about the anatomy and though behind
the workings of GPG. I really liked Neal Walfield&rsquo;s <a href="https://begriffs.com/posts/2016-11-05-advanced-intro-gnupg.html">Advanced Intro to GnuPG</a>.</p>
<h2 id="playground">Playground</h2>
<p>If you just run a GPG command like <code>gpg -K</code> you usually use your <code>~/.gnupg/</code> (on
Linux). To use another, temporary, and clean configuration directory you can set
<code>GNUPGHOME</code>. You can export it like in the following or provide the <code>--homedir</code>
argument for every call to GPG.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>export GNUPGHOME<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>mktemp -d -t gnupg_<span style="color:#66d9ef">$(</span>date +%Y%m%d%H%M<span style="color:#66d9ef">)</span>_XXX<span style="color:#66d9ef">)</span>
</span></span></code></pre></div><h2 id="actions-of-keys">Actions of Keys</h2>
<p>You might guess that there are at least two actions a key can be used for:
signing (a message) and encrypting a message.<br>
But GPG defines two more actions: certifying and authentication<br>
You can have separate keys for all four actions or you can combine sign, certify
(signing keys), and authenticate (signing for SSH authentication). Signing and
certifying are often combined, but I prefer to have a dedicated primary/certify
key, to be able to move it off my devices. This is called &ldquo;offline&rdquo;; more on
that later.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e"># generating primary key, valid for 1 year, this could also be 2006-01-02</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># use a secure passphrase</span>
</span></span><span style="display:flex;"><span>gpg --quick-gen-key your@email.example ed25519 cert 1y
</span></span><span style="display:flex;"><span><span style="color:#75715e"># generate sub key for signing and encryption (requires primary passphrase)</span>
</span></span><span style="display:flex;"><span>gpg --quick-add-key 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A ed25519 sign 1y
</span></span><span style="display:flex;"><span>gpg --quick-add-key 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A cv25519 encr 1y
</span></span></code></pre></div><p>You can not now take a look a your key. The normal way or with more details:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ gpg -K your@email.example
</span></span><span style="display:flex;"><span>sec   ed25519 2025-01-05 [C] [expires: 2026-01-05]
</span></span><span style="display:flex;"><span>      8CE453902E8E810DB46B8A5550ED5BF8E4042B5A
</span></span><span style="display:flex;"><span>uid           [ultimate] your@email.example
</span></span><span style="display:flex;"><span>ssb   ed25519 2025-01-05 [S] [expires: 2026-01-05]
</span></span><span style="display:flex;"><span>ssb   cv25519 2025-01-05 [E] [expires: 2026-01-05]
</span></span></code></pre></div><p>There are a few things to talk about. The new key only has one <code>uid</code>, you can
however add more, for multiple email addresses. This also shows that you
trust this key ultimate-ly. Only trust your own keys to that level. But more to
that later.</p>
<p>The <code>sec</code> shows the private primary key, <code>ssb</code> the private subkey.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ gpg -k your@email.example
</span></span><span style="display:flex;"><span>pub   ed25519 2025-01-05 [C] [expires: 2026-01-05]
</span></span><span style="display:flex;"><span>      8CE453902E8E810DB46B8A5550ED5BF8E4042B5A
</span></span><span style="display:flex;"><span>uid           [ultimate] your@email.example
</span></span><span style="display:flex;"><span>sub   ed25519 2025-01-05 [S] [expires: 2026-01-05]
</span></span><span style="display:flex;"><span>sub   cv25519 2025-01-05 [E] [expires: 2026-01-05]
</span></span></code></pre></div><p>For this key and for imported public keys you can also see <code>pub</code> for the primary
key and <code>sub</code> for the public subkey.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ gpg --keyid-format 0xlong -K --with-subkey-fingerprint --with-keygrip your@email.example
</span></span><span style="display:flex;"><span>sec   ed25519/0x50ED5BF8E4042B5A 2025-01-05 [C] [expires: 2026-01-05]
</span></span><span style="display:flex;"><span>      8CE453902E8E810DB46B8A5550ED5BF8E4042B5A
</span></span><span style="display:flex;"><span>      Keygrip = 2BFDFFC57B771DCE7F009C3BEF37142EBCF4B8E5
</span></span><span style="display:flex;"><span>uid                   [ultimate] your@email.example
</span></span><span style="display:flex;"><span>ssb   ed25519/0xB654F428066CB8A3 2025-01-05 [S] [expires: 2026-01-05]
</span></span><span style="display:flex;"><span>      149A02287C20580A7CF01CAAB654F428066CB8A3
</span></span><span style="display:flex;"><span>      Keygrip = 82887047B2E87C91CC4EA9915D22A6C4D5B23006
</span></span><span style="display:flex;"><span>ssb   cv25519/0x587AE7468688C837 2025-01-05 [E] [expires: 2026-01-05]
</span></span><span style="display:flex;"><span>      3782DF5CA1038377F172D881587AE7468688C837
</span></span><span style="display:flex;"><span>      Keygrip = A57B578C56165F6EFFBC1249DDE4E69F0553D433
</span></span></code></pre></div><p>When using your GPG key you usually reference the primary key and GPG selects
the most recent subkey to do the actual work. If you have only one sub key of a
kind, there cannot be any confusion, but if you have multiple subkeys you can
also reference a specific subkey with <code>SUBKEYFINGERPRINT!</code>.<br>
Also note that the <code>0xlong</code> format uses the ending of the full keyid, not the
start. The <code>long</code> version is often what you see when referring to keys.<br>
The keygrip is what you will see on the file system. In
<code>${GNUPGHOME:-$HOME/.gnupg}/private-keys-v1.d/</code> you can find <code>${keygrip}.key</code>.</p>
<h2 id="list-packets">List Packets</h2>
<p>GPG was designed to process messages in one pass and not require loading the
entire messages into memory. It works on streams of packages in a specific
order. This means, if you want decrypt something, the information about which
key needs to be used comes first.</p>
<h3 id="message">Message</h3>
<p>Looking at a simple message (a new line), encrypting it to our newly created
key, and then inspecting its packets.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ echo |gpg -aer 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A |gpg --list-packets
</span></span><span style="display:flex;"><span>gpg: encrypted with cv25519 key, ID 587AE7468688C837, created 2025-01-05
</span></span><span style="display:flex;"><span>      &#34;your@email.example&#34;
</span></span><span style="display:flex;"><span># off<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> ctb<span style="color:#f92672">=</span><span style="color:#ae81ff">84</span> tag<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> hlen<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> plen<span style="color:#f92672">=</span><span style="color:#ae81ff">94</span>
</span></span><span style="display:flex;"><span>:pubkey enc packet: version 3, algo 18, keyid 587AE7468688C837
</span></span><span style="display:flex;"><span>        data: [263 bits]
</span></span><span style="display:flex;"><span>        data: [392 bits]
</span></span><span style="display:flex;"><span># off<span style="color:#f92672">=</span><span style="color:#ae81ff">96</span> ctb<span style="color:#f92672">=</span>d4 tag<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span> hlen<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> plen<span style="color:#f92672">=</span><span style="color:#ae81ff">70</span> new-ctb
</span></span><span style="display:flex;"><span>:aead encrypted packet: cipher=9 aead=2 cb=16
</span></span><span style="display:flex;"><span>        length: 70
</span></span><span style="display:flex;"><span># off<span style="color:#f92672">=</span><span style="color:#ae81ff">117</span> ctb<span style="color:#f92672">=</span>a3 tag<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span> hlen<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> plen<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> indeterminate
</span></span><span style="display:flex;"><span>:compressed packet: algo=2
</span></span><span style="display:flex;"><span># off<span style="color:#f92672">=</span><span style="color:#ae81ff">119</span> ctb<span style="color:#f92672">=</span>cb tag<span style="color:#f92672">=</span><span style="color:#ae81ff">11</span> hlen<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> plen<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span> new-ctb
</span></span><span style="display:flex;"><span>:literal data packet:
</span></span><span style="display:flex;"><span>        mode b (62), created 1736115332, name=&#34;&#34;,
</span></span><span style="display:flex;"><span>        raw data: 1 bytes
</span></span></code></pre></div><p>The first two lines are printed to stderr and show information about the
encrypted message. Then there follow four packets.</p>
<ul>
<li>The first one is information about the public key used — note that the keyid
is not the primary key but the id of the subkey for encryption.</li>
<li>The second one is a asymmetrically encrypted packet containing the symmetric
session key to decrypt the message. If you &ldquo;asymmetrically&rdquo; encrypt a message
to multiple recipients, all it does is encrypt the symmetric key multipel
times. This way the message does not have to be duplicated.<br>
There is debate about if you should use AEAD due to a split between GnuPG and
the OpenPGP specification it is based on. TL;DR: <a href="https://security.stackexchange.com/questions/275883/should-one-really-disable-aead-for-recent-gnupg-created-pgp-keys">disable it for now</a>.
<ul>
<li>Side note: Should you ever be forced to to decrypt data encrypted to you,
you should <a href="https://www.youtube.com/watch?v=dQw4w9WgXcQ">never give up</a> your entire secret key, but only decrypt relevant
session keys. This way your key is not compromised.</li>
</ul>
</li>
<li>The third packets contains the fourth packet, as far as I know. I am not an
expert on GPG but as far as I understood it, there is a hierarchy to packets,
but I could not find an easy way to show that.</li>
<li>The fourth packet is the actual encrypted data that can be decrypted with the
decrypted symmetric key from earlier.</li>
</ul>
<p>Note: Also try the command from above with <code>-vv</code>.</p>
<p>Now try the same with <code>echo | gpg -s | gpg --list-packets</code>. You will three
packets: onepass_sig, literal data, and signature.<br>
The onepass_sig packet is useful for checking the signature in one pass. This
way the hash for for the signature can be calculated while the message is
already in memory.</p>
<h3 id="key">Key</h3>
<p>You can do the same on public and secret keys.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ gpg --export your@email.example -a |gpg --list-packets
</span></span><span style="display:flex;"><span># off<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> ctb<span style="color:#f92672">=</span><span style="color:#ae81ff">98</span> tag<span style="color:#f92672">=</span><span style="color:#ae81ff">6</span> hlen<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> plen<span style="color:#f92672">=</span><span style="color:#ae81ff">51</span>
</span></span><span style="display:flex;"><span>:public key packet:
</span></span><span style="display:flex;"><span>        version 4, algo 22, created 1736114781, expires 0
</span></span><span style="display:flex;"><span>        pkey[0]: [80 bits] ed25519 (1.3.6.1.4.1.11591.15.1)
</span></span><span style="display:flex;"><span>        pkey[1]: [263 bits]
</span></span><span style="display:flex;"><span>        keyid: 50ED5BF8E4042B5A
</span></span><span style="display:flex;"><span># off<span style="color:#f92672">=</span><span style="color:#ae81ff">53</span> ctb<span style="color:#f92672">=</span>b4 tag<span style="color:#f92672">=</span><span style="color:#ae81ff">13</span> hlen<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> plen<span style="color:#f92672">=</span><span style="color:#ae81ff">18</span>
</span></span><span style="display:flex;"><span>:user ID packet: &#34;your@email.example&#34;
</span></span><span style="display:flex;"><span># off<span style="color:#f92672">=</span><span style="color:#ae81ff">73</span> ctb<span style="color:#f92672">=</span><span style="color:#ae81ff">88</span> tag<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> hlen<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> plen<span style="color:#f92672">=</span><span style="color:#ae81ff">153</span>
</span></span><span style="display:flex;"><span>:signature packet: algo 22, keyid 50ED5BF8E4042B5A
</span></span><span style="display:flex;"><span>        version 4, created 1736114781, md5len 0, sigclass 0x13
</span></span><span style="display:flex;"><span>        digest algo 10, begin of digest 13 2e
</span></span><span style="display:flex;"><span>        hashed subpkt 33 len 21 (issuer fpr v4 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A)
</span></span><span style="display:flex;"><span>        hashed subpkt 2 len 4 (sig created 2025-01-05)
</span></span><span style="display:flex;"><span>        hashed subpkt 27 len 1 (key flags: 01)
</span></span><span style="display:flex;"><span>        hashed subpkt 9 len 4 (key expires after 1y0d0h0m)
</span></span><span style="display:flex;"><span>        hashed subpkt 11 len 4 (pref-sym-algos: 9 8 7 2)
</span></span><span style="display:flex;"><span>        hashed subpkt 34 len 1 (pref-aead-algos: 2)
</span></span><span style="display:flex;"><span>        hashed subpkt 21 len 5 (pref-hash-algos: 10 9 8 11 2)
</span></span><span style="display:flex;"><span>        hashed subpkt 22 len 3 (pref-zip-algos: 2 3 1)
</span></span><span style="display:flex;"><span>        hashed subpkt 30 len 1 (features: 07)
</span></span><span style="display:flex;"><span>        hashed subpkt 23 len 1 (keyserver preferences: 80)
</span></span><span style="display:flex;"><span>        subpkt 16 len 8 (issuer key ID 50ED5BF8E4042B5A)
</span></span><span style="display:flex;"><span>        data: [254 bits]
</span></span><span style="display:flex;"><span>        data: [256 bits]
</span></span><span style="display:flex;"><span># off<span style="color:#f92672">=</span><span style="color:#ae81ff">228</span> ctb<span style="color:#f92672">=</span>b8 tag<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span> hlen<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> plen<span style="color:#f92672">=</span><span style="color:#ae81ff">51</span>
</span></span><span style="display:flex;"><span>:public sub key packet:
</span></span><span style="display:flex;"><span>        version 4, algo 22, created 1736114906, expires 0
</span></span><span style="display:flex;"><span>        pkey[0]: [80 bits] ed25519 (1.3.6.1.4.1.11591.15.1)
</span></span><span style="display:flex;"><span>        pkey[1]: [263 bits]
</span></span><span style="display:flex;"><span>        keyid: B654F428066CB8A3
</span></span><span style="display:flex;"><span># off<span style="color:#f92672">=</span><span style="color:#ae81ff">281</span> ctb<span style="color:#f92672">=</span><span style="color:#ae81ff">88</span> tag<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> hlen<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> plen<span style="color:#f92672">=</span><span style="color:#ae81ff">245</span>
</span></span><span style="display:flex;"><span>:signature packet: algo 22, keyid 50ED5BF8E4042B5A
</span></span><span style="display:flex;"><span>        version 4, created 1736114906, md5len 0, sigclass 0x18
</span></span><span style="display:flex;"><span>        digest algo 10, begin of digest 50 5d
</span></span><span style="display:flex;"><span>        hashed subpkt 33 len 21 (issuer fpr v4 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A)
</span></span><span style="display:flex;"><span>        hashed subpkt 2 len 4 (sig created 2025-01-05)
</span></span><span style="display:flex;"><span>        hashed subpkt 27 len 1 (key flags: 02)
</span></span><span style="display:flex;"><span>        hashed subpkt 9 len 4 (key expires after 1y0d0h0m)
</span></span><span style="display:flex;"><span>        subpkt 16 len 8 (issuer key ID 50ED5BF8E4042B5A)
</span></span><span style="display:flex;"><span>        subpkt 32 len 117 (signature: v4, class 0x19, algo 22, digest algo 10)
</span></span><span style="display:flex;"><span>        data: [256 bits]
</span></span><span style="display:flex;"><span>        data: [255 bits]
</span></span><span style="display:flex;"><span># off<span style="color:#f92672">=</span><span style="color:#ae81ff">528</span> ctb<span style="color:#f92672">=</span>b8 tag<span style="color:#f92672">=</span><span style="color:#ae81ff">14</span> hlen<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> plen<span style="color:#f92672">=</span><span style="color:#ae81ff">56</span>
</span></span><span style="display:flex;"><span>:public sub key packet:
</span></span><span style="display:flex;"><span>        version 4, algo 18, created 1736114910, expires 0
</span></span><span style="display:flex;"><span>        pkey[0]: [88 bits] cv25519 (1.3.6.1.4.1.3029.1.5.1)
</span></span><span style="display:flex;"><span>        pkey[1]: [263 bits]
</span></span><span style="display:flex;"><span>        pkey[2]: [32 bits]
</span></span><span style="display:flex;"><span>        keyid: 587AE7468688C837
</span></span><span style="display:flex;"><span># off<span style="color:#f92672">=</span><span style="color:#ae81ff">586</span> ctb<span style="color:#f92672">=</span><span style="color:#ae81ff">88</span> tag<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> hlen<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span> plen<span style="color:#f92672">=</span><span style="color:#ae81ff">126</span>
</span></span><span style="display:flex;"><span>:signature packet: algo 22, keyid 50ED5BF8E4042B5A
</span></span><span style="display:flex;"><span>        version 4, created 1736114910, md5len 0, sigclass 0x18
</span></span><span style="display:flex;"><span>        digest algo 10, begin of digest 73 9c
</span></span><span style="display:flex;"><span>        hashed subpkt 33 len 21 (issuer fpr v4 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A)
</span></span><span style="display:flex;"><span>        hashed subpkt 2 len 4 (sig created 2025-01-05)
</span></span><span style="display:flex;"><span>        hashed subpkt 27 len 1 (key flags: 0C)
</span></span><span style="display:flex;"><span>        hashed subpkt 9 len 4 (key expires after 1y0d0h0m)
</span></span><span style="display:flex;"><span>        subpkt 16 len 8 (issuer key ID 50ED5BF8E4042B5A)
</span></span><span style="display:flex;"><span>        data: [256 bits]
</span></span><span style="display:flex;"><span>        data: [256 bits]
</span></span></code></pre></div><ul>
<li>The first packet is the public or secret key (depending on what you looked
at). You might spot <code>expires 0</code>. This means no expiration but will be
overwritten later.</li>
<li>The second packet is the user id.</li>
<li>The third packet is probably the most interesting packet as it is the
signature of the two earlier packets and contains the settings for the key,
like preferred algorithms and the expiration. This is the reason why you can
easily change the expiration on a key without invalidating the key or
invalidating signatures of the key and uid: The key stays the same, only the
signature changes. Every uid get its own signature, so it can be easily
removed.</li>
<li>Then the two subkeys follow, first the public/secret key itself,…</li>
<li>…then the signature from the primary key that also tells others that these are
subkeys of the primary key and other settings. This means, that to change
expiration of the subkeys, you need the primary key.
These keys are not special to the primary key. In fact, it is possible to
reuse the same same subkeys and recertify them to another primary key (should
you have lost the old one). There is also other black magic you can do.
Signing keys also <a href="https://www.gnupg.org/faq/subkey-cross-certify.html">cross-sign</a> the primary key to prevent someone pretending
that the subkey is theirs.</li>
</ul>
<h2 id="offline-keys-and-a-yubikey">Offline Keys and a YubiKey</h2>
<p>Generally offline key only means, that it is currently not on the device. It
could be on another computer, on a flash drive, or a smart card like a YubiKey.
It is generally recommended to use an offline primary key, but any key could be
offline.<br>
Having an offline primary key comes with some caveats. While you can use all
other keys normally, you cannot create, revoke, sign other keys, or change
subkeys or uids. This includes settings, e.g. expiration.</p>
<p>It is important to understand that a smartcard or a YubiKey with smartcard
functionality a key only goes one way. You can store a key on a smartcard/YK but
you can never retrieve it (in lieu of exploits). This is very much intentional,
as the idea of smartcards is to do the secure computing on the card and never
load any secrets into comptuer memory. This is by design how it is supposed to
work.<br>
This is why you need to watch out for the command <code>addtocard</code> which saves the
key to the smartcard and deletes the key from disk. Meaning you can never backup
that key again, if you do not have a backup already. The same applies if you
generate the key on the smartcard — your computer will never see the contents of
that key.</p>
<p>Another limitation of my YubiKey is, that it only has three key slots. One for
a signature key, one for an encryption key, one for an authentication key. So if
you use separate keys for certify and sign, you are SOL because you can only put
one into the signing slot. In my case I put the primary key into the signature
slot as an additional backup and to be able to manage subkeys more easily
without needing to go to the true offline primary key.</p>
<p>If you see <code>sec#</code>, the primary key is not on the device. If you see <code>sec&gt;</code> the
primary key is on a smartcard (if you look at the keygrip file you will find a
stub instead of the actual key).</p>
<h3 id="backup-and-removal-of-key">Backup and Removal of Key</h3>
<p>There is something more important than backing up your encrypted email — backing
up your secret keys. The easiest way is to just backup the entire <code>GNUPGHOME</code>,
usually <code>~/.gnupg/</code>. In my case I have LUKS encrypted flash drive I copy it to.
All usual backup practices apply — 3-2-1, in case your house gets struck by
lightning while the flash drive is inserted into your computer.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>DATE<span style="color:#f92672">=</span><span style="color:#66d9ef">$(</span>date +%F<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>mkdir /run/media/syphdias/LUKS001/gpg/.gnupg-$DATE
</span></span><span style="display:flex;"><span>rsync -aP ~/.gnupg/ /run/media/syphdias/LUKS001/gpg/.gnupg-$DATE
</span></span></code></pre></div><p>I use the date, in case I mess something up, during renewal. Now we remove the
primary key from our keyring on the device. We already found the keygrip when
looking at our keys.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ rm ~/.gnupg/private-keys-v1.d/2BFDFFC57B771DCE7F009C3BEF37142EBCF4B8E5.key
</span></span><span style="display:flex;"><span>❯ GNUPGHOME=gnupg_202501051540_gqK/ gpg -K
</span></span><span style="display:flex;"><span>/home/syphdias/.gnupg/pubring.kbx
</span></span><span style="display:flex;"><span>--------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>sec#  ed25519 2025-01-05 [C] [expires: 2026-01-05]
</span></span><span style="display:flex;"><span>      8CE453902E8E810DB46B8A5550ED5BF8E4042B5A
</span></span><span style="display:flex;"><span>uid           [ultimate] your@email.example
</span></span><span style="display:flex;"><span>ssb   ed25519 2025-01-05 [S] [expires: 2026-01-05]
</span></span><span style="display:flex;"><span>ssb   cv25519 2025-01-05 [E] [expires: 2026-01-05]
</span></span></code></pre></div><p>Seeing <code>sec#</code> shows the successful removal of the primary key. Keep in mind the
caveats from above.</p>
<h3 id="renewing-with-offline-key">Renewing with Offline Key</h3>
<p>A year has passed and you are still into GPG for some nerdish reason and want to
keep working with out keys without regenerating completely new ones.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ cd /run/media/syphdias/LUKS001/gpg/
</span></span><span style="display:flex;"><span>❯ cp -r .gnupg-2024-01-10/ .gnupg-2025-01-14/
</span></span><span style="display:flex;"><span>❯ # only work on a copy of your backup for safety
</span></span><span style="display:flex;"><span>❯ gpg --quick-set-expire
</span></span><span style="display:flex;"><span>usage: gpg [options] --quick-set-exipre FINGERPRINT EXPIRE [SUBKEY-FPRS]
</span></span><span style="display:flex;"><span>❯ # renew primary key
</span></span><span style="display:flex;"><span>❯ GNUPGHOME=.gnupg-2025-01-14 gpg --quick-set-expire 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A 2027-01-05
</span></span><span style="display:flex;"><span>❯ # renew subkeys
</span></span><span style="display:flex;"><span>❯ GNUPGHOME=.gnupg-2025-01-14 gpg --quick-set-expire 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A 2027-01-05 149A02287C20580A7CF01CAAB654F428066CB8A3 3782DF5CA1038377F172D881587AE7468688C837
</span></span></code></pre></div><p>You can use <code>GNUPGHOME=.gnupg-2025-01-14 gpg -K</code> this worked. If you wanted you
could also change other attributes at this time, like preferred algorithms, or
add another uid. If we are happy with the keyring, you can keep the directory as
backup to copy for next year.</p>
<p>There are a few ways how you could get the renewed offline keys to your
machine(s) now. You could copy the subkeys by keygrip — dont! Or copy over the
entire keyring and remove the primary key again — meh! The proper way is to
export the secret subkeys only and import them into your current keyring.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ # check if you will import what you wanted
</span></span><span style="display:flex;"><span>❯ GNUPGHOME=.gnupg-2025-01-14 gpg --export-secret-subkeys --export-options export-minimal 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A |gpg --import --import-options show-only
</span></span><span style="display:flex;"><span>❯ GNUPGHOME=.gnupg-2025-01-14 gpg --export-secret-subkeys --export-options export-minimal 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A |gpg --import
</span></span><span style="display:flex;"><span>❯ # if you published your GPG key, update the published key
</span></span><span style="display:flex;"><span>❯ gpg --send-keys 8CE453902E8E810DB46B8A5550ED5BF8E4042B5A
</span></span></code></pre></div><p>You could only export certain subkeys, if you wanted. Or, if you have multiple
uids, you could also filter your export with <code>--export-filter keep-ui=mbox=your@email.example</code>. To check your export you can check the import
without importing by using the command <code>gpg --import --import-opstions show-only</code>. This can also be useful for others&rsquo; public keys.</p>
<p>Every time you change settings of your GPG key, you create a new signature. With
<code>--export-optitons export-minimal</code> removes all signatures except the most recent
one.</p>
<h3 id="moving-key-to-yubikey">Moving Key to YubiKey</h3>
<p>If you want to have your primary key not just in your backup, you can edit your
key (<code>gpg --edit-key KEY</code>) and select <code>keytocard</code>. Leave with <code>save</code>. From then
on you can use the key on the YubiKey. Keep in mind that there are only three
key slots. I mainly have this a additional backup of my primary key and to be
able to use the primary key to manage subkeys that I might not need in my backup
and to set settings on-the-fly without requiring my true offline primary key.</p>
<h2 id="publishing-to-a-keyserver">Publishing to a Keyserver</h2>
<p>Keyservers were very open in the past. You just uploaded your key to them and
there were forever findable and others could upload their signatures for other
keys, etc. This is kinda dead. For one you could DOS someone with overwhelming
their key with signature. This was basically the last nail in the coffin for the
Web of Trust.  Another reason the traditional keyservers are no longer around is
the GDPR which requires the option to remove personal identifiable data on
request. Today you can either publish your GPG in a place you think proper for
people to manually find it, use <a href="https://www.gnupg.org/blog/20160830-web-key-service.html">Web Key Directory</a> (WKD) to store keys on your
website at <code>/.well-known/openpgpkey/hu/hash-of-uid</code>, or <a href="https://keys.openpgp.org/about/usage">upload your key to
https://keys.openpgp.org</a> where you will also need to verify your email
address.</p>
<h2 id="misc">Misc</h2>
<p>In the past GPG wanted key owners verifying each other&rsquo;s keys and establish a
&ldquo;Web of Trust&rdquo; in key signing parties. This did not take hold and is basically
nerd sports for enthusiasts that do it for the fun of it. The practical
application is basically dead. Trust on first use (TOFU) is easier in practice
with less overhead. You can combine the two modes by setting <code>trust-model tofu+pgp</code> in your <code>${GNUPGHOME:-$HOME/.gnupg}/gpg.conf</code>.</p>
<p>YubiKeys has more uses than acting as a smartcard for GPG.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ ykman --device 12345678 info
</span></span><span style="display:flex;"><span>WARNING: PC/SC not available. Smart card (CCID) protocols will not function.
</span></span><span style="display:flex;"><span>ERROR: Unable to list devices for connection
</span></span><span style="display:flex;"><span>Device type: YubiKey 5C NFC
</span></span><span style="display:flex;"><span>Serial number: 12345678
</span></span><span style="display:flex;"><span>Firmware version: 5.4.3
</span></span><span style="display:flex;"><span>Form factor: Keychain (USB-C)
</span></span><span style="display:flex;"><span>Enabled USB interfaces: OTP, FIDO, CCID
</span></span><span style="display:flex;"><span>NFC transport is enabled
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>Applications    USB     NFC
</span></span><span style="display:flex;"><span>Yubico OTP      Enabled Enabled
</span></span><span style="display:flex;"><span>FIDO U2F        Enabled Enabled
</span></span><span style="display:flex;"><span>FIDO2           Enabled Enabled
</span></span><span style="display:flex;"><span>OATH            Enabled Enabled
</span></span><span style="display:flex;"><span>PIV             Enabled Enabled
</span></span><span style="display:flex;"><span>OpenPGP         Enabled Enabled
</span></span><span style="display:flex;"><span>YubiHSM Auth    Enabled Enabled
</span></span></code></pre></div><h2 id="settings">Settings</h2>
<p>There are a few settings I think you should take a look at in the
<code>~/.gnupg/gpg.conf</code> file.</p>
<pre tabindex="0"><code class="language-conf" data-lang="conf"># If you do not set this option the first secret key found will be used
default-key YOURKEYID
# If you encrypt someone, you will never again be able to decrypt it. This can
# be a feature to be anonymous, but can be a pain, if you use this to send
# emails and still want to be able to read your sent emails.
default-recipient-self
# disable comments in clear text signatures and ASCII armored messages
no-comments
# default to long format
keyid-format 0xlong
# try GPG agent before asking for passphrase
use-agent
# use TOFU and WOT/PGP
trust-model tofu+pgp
# used for --(recv|send|search)-keys
keyserver hkps://keys.openpgp.org:443/
</code></pre><p>I will not include any cipher preferences as they will go out of date.</p>
<h2 id="best-ish-practices">Best-ish Practices</h2>
<p>…as far as I can tell.</p>
<ul>
<li>use secure passphrases</li>
<li>reference key by long format (opposed to short id or email)</li>
<li>again, <em>always</em> set expiration for all keys</li>
<li>create revoke file for your primary key <code>gpg --gen-revoke KEY</code></li>
<li><a href="http://web.archive.org/web/20201020082313/https://debian-administration.org/users/dkg/weblog/97">do not use comment field</a></li>
<li>maybe use name field — peoples opinions vary</li>
</ul>
<h2 id="further-reading">Further Reading</h2>
<p>There is probably more that I want to write but at some point it just has to be
another day, another post.</p>
<p>I can recommend drduh&rsquo;s <a href="https://github.com/drduh/YubiKey-Guide">YubiKey-Guide</a>. If you want to use a YubiKey at least
give it a skim. And if you got your YubiKey, read it whole.</p>
]]></content:encoded></item><item><title>They Say Don't Use the AUR</title><link>https://www.relg.uk/posts/they-say-dont-use-the-aur/</link><pubDate>Sun, 08 Oct 2023 17:41:04 +0200</pubDate><guid>https://www.relg.uk/posts/they-say-dont-use-the-aur/</guid><description>&lt;p>If I had to guess, why people use an Arch-based system, I would guess a big
reason would be the AUR — even though it is not officially supported. It is a
big part of the community and the appeal of Arch. This is a story how the AUR
can break some things and the reason it is not officially supported.&lt;/p>
&lt;p>It all started with a normal update. In my case I used the AUR helper &lt;a href="https://github.com/Morganamilo/paru">&lt;code>paru&lt;/code>&lt;/a>
to update all system packages and all AUR packages. Only &lt;code>obs-studio-tytan652&lt;/code>
failed when trying to compile, but I rarely use OBS Studio (it will get fixed,
eventually).&lt;/p></description><content:encoded><![CDATA[<p>If I had to guess, why people use an Arch-based system, I would guess a big
reason would be the AUR — even though it is not officially supported. It is a
big part of the community and the appeal of Arch. This is a story how the AUR
can break some things and the reason it is not officially supported.</p>
<p>It all started with a normal update. In my case I used the AUR helper <a href="https://github.com/Morganamilo/paru"><code>paru</code></a>
to update all system packages and all AUR packages. Only <code>obs-studio-tytan652</code>
failed when trying to compile, but I rarely use OBS Studio (it will get fixed,
eventually).</p>
<h2 id="broken-electron-based-applications">Broken Electron-based Applications</h2>
<p>When I tried to launch my note taking app <a href="https://obsidian.md/">Obsidian</a>, it never started. I
dropped into a shell and tried again.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ obsidian
</span></span><span style="display:flex;"><span>/usr/lib/electron25/electron: error while loading shared libraries: libdav1d.so.6: cannot open shared object file: No such file or directory
</span></span></code></pre></div><p>I had seem behavior like this before after an update. When you update your
kernel and you are still running the old kernel. If the running (old) kernel
needs to load a new module it expects the old libraries but cannot find them as
only the new ones are available.</p>
<p>It is generally also a bad idea to symlink libraries. If you would symlink the
old library to the location of the old one, there is no guarantee that they are
even remotely compatible.</p>
<blockquote>
<p><strong>Tip 1</strong>: Don&rsquo;t break your system with symlinking shared libraries.</p>
</blockquote>
<p>For the new-kernel-old-module problem a reboot usually suffices. However,
electron apps would probably not use any kernel shared libraries. To make sure
anyways, I did reboot.</p>
<blockquote>
<p><strong>Tip 2</strong>: Reboot after a upgrade if libraries cannot be found.</p>
</blockquote>
<p>After the reboot I was still not able to launch Obsidian or any other
Electron-based app.</p>
<blockquote>
<p><strong>Electron</strong> is a framework for building desktop applications. It uses the
Chromium browser engine and Node.js to make it easy to build cross-platform
applications — especially, if you are already familiar with building web apps.</p>
</blockquote>
<h2 id="what-is-actually-missing-and-where-should-it-come-from">What is Actually Missing and Where Should it Come From?</h2>
<p>Since the issue seems to come from [electon] and not Obsidian itself I looked at
electron directly which yielded the same error.</p>
<p>When looking for library dependencies for the command <code>electron</code>, there are two
red herrings. One is, that the package <code>electron</code> is only a meta package to
<a href="https://gitlab.archlinux.org/archlinux/packaging/packages/electron/-/blob/main/PKGBUILD?ref_type=heads">link to the latest stable version of electron</a> The second red herring is that
<code>/usr/bin/electron25</code> is a shell script to exec <code>/usr/lib/electron25/electron</code>.
So to check for the shared library dependencies, we can follow the trail like
this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ which electron
</span></span><span style="display:flex;"><span>/usr/bin/electron
</span></span><span style="display:flex;"><span>❯ ls -l /usr/bin/electron
</span></span><span style="display:flex;"><span>lrwxrwxrwx 1 root root 10 Jun 16 08:50 /usr/bin/electron -&gt; electron25
</span></span><span style="display:flex;"><span>❯ file /usr/bin/electron25
</span></span><span style="display:flex;"><span>/usr/bin/electron25: Bourne-Again shell script, ASCII text executable
</span></span><span style="display:flex;"><span>❯ cat /usr/bin/electron25
</span></span><span style="display:flex;"><span>#!/usr/bin/bash
</span></span><span style="display:flex;"><span>[…snip…]
</span></span><span style="display:flex;"><span>name=electron25
</span></span><span style="display:flex;"><span>[…snip…]
</span></span><span style="display:flex;"><span>exec /usr/lib/${name}/electron &#34;${flags[@]}&#34; &#34;$@&#34;
</span></span><span style="display:flex;"><span>❯ file /usr/lib/electron25/electron
</span></span><span style="display:flex;"><span>/usr/lib/electron25/electron: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 4.4.0, BuildID[sha1]=adabc98fbf2c1422ad6b6c4de371150f4fe605aa, stripped
</span></span></code></pre></div><blockquote>
<p><strong>Tip 3</strong>: Find the binary that is actually run.</p>
</blockquote>
<p>To find the libraries you can run <code>ldd</code> and filtered for the library name.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ ldd /usr/lib/electron25/electron | grep libdav1d
</span></span><span style="display:flex;"><span>	libdav1d.so.7 =&gt; /usr/lib/libdav1d.so.7 (0x00007f41ea424000)
</span></span><span style="display:flex;"><span>❯ ls -l /usr/lib/libdav1d.so.7
</span></span><span style="display:flex;"><span>lrwxrwxrwx 1 root root 17 Oct  4 17:21 /usr/lib/libdav1d.so.7 -&gt; libdav1d.so.7.0.0
</span></span><span style="display:flex;"><span>❯ pacman -F /usr/lib/libdav1d.so.7
</span></span><span style="display:flex;"><span>usr/lib/libdav1d.so.7 is owned by extra/dav1d 1.3.0-1
</span></span></code></pre></div><p>Let&rsquo;s walk through this. The binary wants <code>libdav1d.so.7</code> and it can be found in
<code>/usr/lib/</code>. The way this resolution from filename to path works is similar to
how the <code>PATH</code> variable works. If you want to learn more about where libraries
live, search for <code>LS_LIBRARY_PATH</code> and <code>ld</code>. For now, it is enough to know that
the library is present at a know location, and points to another (existing)
file.</p>
<p>But actually this library is not the one the error complains about. In the error
above it complained about <code>libdav1d.so.6</code> being absent.</p>
<p>I reached out to the Arch Linux Mailing List which was very helpful. With the
help of <code>lddtree</code> (from the package <code>pax-utils</code>) I could look recursively at the
required libraries. Again, I filtered for the relevant library name but show 5
lines above the matches to see potential parent dependencies.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ lddtree /usr/lib/electron25/electron | grep -B5 libdav1d
</span></span><span style="display:flex;"><span>    libavcodec.so.60 =&gt; /usr/lib/libavcodec.so.60
</span></span><span style="display:flex;"><span>        libswresample.so.4 =&gt; /usr/lib/libswresample.so.4
</span></span><span style="display:flex;"><span>            libsoxr.so.0 =&gt; /usr/lib/libsoxr.so.0
</span></span><span style="display:flex;"><span>                libgomp.so.1 =&gt; /usr/lib/libgomp.so.1
</span></span><span style="display:flex;"><span>        libvpx.so.8 =&gt; /usr/lib/libvpx.so.8
</span></span><span style="display:flex;"><span>        libdav1d.so.6 =&gt; None
</span></span><span style="display:flex;"><span>--
</span></span><span style="display:flex;"><span>        libva-x11.so.2 =&gt; /usr/lib/libva-x11.so.2
</span></span><span style="display:flex;"><span>            libX11-xcb.so.1 =&gt; /usr/lib/libX11-xcb.so.1
</span></span><span style="display:flex;"><span>            libxcb-dri3.so.0 =&gt; /usr/lib/libxcb-dri3.so.0
</span></span><span style="display:flex;"><span>        libvdpau.so.1 =&gt; /usr/lib/libvdpau.so.1
</span></span><span style="display:flex;"><span>        libOpenCL.so.1 =&gt; /usr/lib/libOpenCL.so.1
</span></span><span style="display:flex;"><span>    libdav1d.so.7 =&gt; /usr/lib/libdav1d.so.7
</span></span></code></pre></div><p>This still shows <code>libdav1d.so.7</code> at the root level of the dependencies but also
<code>libdav1d.so.6</code> as dependency of <code>libavcodec.so.60</code>. It cannot resolve the name
to a library location so <code>None</code> gets displayed.</p>
<p>So where is this library from?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>❯ pacman -F libavcodec.so.60
</span></span><span style="display:flex;"><span>extra/ffmpeg 2:6.0-12
</span></span><span style="display:flex;"><span>    usr/lib/libavcodec.so.60
</span></span><span style="display:flex;"><span>❯ pacman -Qi ffmpeg |grep -e Name -e Prov -e Requi
</span></span><span style="display:flex;"><span>Name            : ffmpeg-obs
</span></span><span style="display:flex;"><span>Provides        : ffmpeg=6.0.r12.ga6dc929  libavcodec.so=60-64  libavdevice.so=60-64  libavfilter.so=9-64  libavformat.so=60-64  libavutil.so=58-64  libpostproc.so=57-64  libswresample.so=4-64  libswscale.so=7-64
</span></span><span style="display:flex;"><span>Required By     : chromaprint  chromium  electron25  ferdium-bin  firefox  gst-libav  krita  obs-studio-tytan652  opencv  peek  qt5-webengine  telegram-desktop  thunderbird  vlc-luajit
</span></span></code></pre></div><p>Hm, do you notice something?</p>
<blockquote>
<p><strong>Tip 4</strong>: You can use <code>ldd</code>, <code>lddtree</code> (<code>pax-utils</code>) to find shared library
dependencies that a binary need (is linked against).</p>
</blockquote>
<blockquote>
<p><strong>Tip 5</strong>: You can use <code>pacman -F</code> to find the package for file and <code>pacman -Qi</code> to show information about a package, like actual name or which other
packages require it.</p>
</blockquote>
<h2 id="the-culprit">The Culprit</h2>
<p>The library is provided by <code>ffmpeg</code> a widely used library for decoding of all
kinds of media. But the installed version is not the regular version from the
official arch (extra) repositories but <a href="https://aur.archlinux.org/packages/ffmpeg-obs"><code>ffmpeg-obs</code></a>, a version from the AUR
which is required by <a href="https://aur.archlinux.org/packages/obs-studio-tytan652"><code>obs-studio-tytan652</code></a>.</p>
<p>So why is it broken? Every time a library is updated, every program that uses
it, needs to also be rebuilt to link against the latest version. If you are
running only official packages from Arch Linux they take good care that if one
library gets an update every program or library using it (recursively) will be
updated as well to reflect the changed version. This is the reason why a
<a href="https://wiki.archlinux.org/title/system_maintenance#Partial_upgrades_are_unsupported">partially upgraded system is unsupported</a>. They cannot guarantee that the
libraries match up.</p>
<p>The AUR on the other hand is independent from the official package repositories.
If something changes in the official repos, the AUR package maintainer need to
notice and react to it. If it is a binary package, they need to rebuild it
themselves. If it is a package built from source it needs to be rebuilt on the
users machine as well as soon as the new libraries are available (can also be
done through a version increment, e.g. increase the suffix to <code>-2</code>).</p>
<p>At this point I had two options.</p>
<ol>
<li>Remove <code>obs-studio-tytan652</code> and switch back to <code>extra/ffmpeg</code> (the
officially) supported version</li>
<li>Rebuilt <code>ffmpeg-obs</code> to link against the latest version of <code>dav1d</code>.</li>
</ol>
<p>When I realised what had happened there was already <a href="https://aur.archlinux.org/cgit/aur.git/commit/?h=ffmpeg-obs&amp;id=8286e7cda14aaa87f9075174fa475907d99ce6bd">a new version</a> of
<code>ffmpeg-obs</code>. But I will keep this in mind for future updates.</p>
<h2 id="conclusion">Conclusion</h2>
<p>If this error had happened in an AUR package I would have known that I probably
had to rebuild it to link to the new dependencies. In this case however, one
package in the dependency chain was replaced by an unofficial one. Which made it
less obvious to track down the issue.</p>
<blockquote>
<p><strong>Tip 6</strong>: Be weary what packages you replace with packages from the AUR.</p>
</blockquote>
]]></content:encoded></item><item><title>First and Last Business Day of the Month With Systemd Timers</title><link>https://www.relg.uk/posts/first-and-last-business-day-of-the-month-with-systemd-timers/</link><pubDate>Tue, 14 Mar 2023 00:00:48 +0100</pubDate><guid>https://www.relg.uk/posts/first-and-last-business-day-of-the-month-with-systemd-timers/</guid><description>&lt;p>I recently was looking for a way to run a systemd service on the last business
day of the month, but I could only find an answer for first business day of
every month on Stack Overflow which was wrong. So I looked into it.&lt;/p>
&lt;p>Spoiler: This is not possible with one calendar expression.&lt;/p>
&lt;p>If you remember only one thing from this blog post, &lt;strong>remember
&lt;code>systemd-analyse&lt;/code>&lt;/strong>. There are quite a few useful subcommands, e.g. &lt;code>verify&lt;/code>.
You should check them out, if you do not know them yet with &lt;code>systemd-analyse -h&lt;/code>.&lt;/p></description><content:encoded><![CDATA[<p>I recently was looking for a way to run a systemd service on the last business
day of the month, but I could only find an answer for first business day of
every month on Stack Overflow which was wrong. So I looked into it.</p>
<p>Spoiler: This is not possible with one calendar expression.</p>
<p>If you remember only one thing from this blog post, <strong>remember
<code>systemd-analyse</code></strong>. There are quite a few useful subcommands, e.g. <code>verify</code>.
You should check them out, if you do not know them yet with <code>systemd-analyse -h</code>.</p>
<p>For timers, we want <code>systemd-analyse calendar</code>.</p>
<h2 id="first-business-day-of-the-month">First Business Day of the Month</h2>
<p>To achieve this we can set <code>OnCalendar</code> twice in the timer unit, we do not need
two timer units:</p>
<pre tabindex="0"><code>[Timer]
OnCalendar=Mon..Fri *-*-01
OnCalendar=Mon *-*-02..03
</code></pre><ul>
<li><code>Mon..Fri *-*-01</code> will activate if the first day of the month is a business
day</li>
<li><code>Mon *-*-02..03</code> will activate if the second or third day of the month is a
Monday. This happens if the first was a Sunday, or if the first was a Saturday
and the second was a Sunday. There is no overlap.</li>
</ul>
<p>To verify this is true we can use (<code>--iterations</code> is optional but very useful):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>systemd-analyze calendar <span style="color:#e6db74">&#39;Mon..Fri *-*-01&#39;</span> <span style="color:#e6db74">&#39;Mon *-*-02..03&#39;</span> --iterations <span style="color:#ae81ff">10</span>
</span></span></code></pre></div><p>The output is a bit unwieldy since it treats both expressions separately and
prints three versions of the iterations.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>systemd-analyze calendar <span style="color:#e6db74">&#39;Mon..Fri *-*-01&#39;</span> <span style="color:#e6db74">&#39;Mon *-*-02..03&#39;</span> --iterations <span style="color:#ae81ff">10</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    |grep Iteration |sort -k4
</span></span></code></pre></div><p>This works for a English locale but it will filter out the first iteration
because it is listed as &ldquo;Next elapse&rdquo;. The get a good overview in this case it
suffices.</p>
<h2 id="last-business-day-of-the-month">Last Business Day of the Month</h2>
<p>Last day is very similar to first day, but requires dates that were introduced
in <a href="https://github.com/systemd/systemd/blob/v233/NEWS#L174">systemd v233</a>. Again, we need two expressions:</p>
<pre tabindex="0"><code>[Timer]
OnCalendar=Mon..Fri *-*~01
OnCalendar=Fri *-*~02..03
</code></pre><ul>
<li><code>Mon..Fri *-*~01</code> triggers if the last day of the month is a business day</li>
<li><code>Fri *-*~02..03</code> triggers if the second to last or third to last day of the
month was a Friday. This happens if the weekend is on the last day of the
month.</li>
</ul>
<p>Verifying this works just the same:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>systemd-analyze calendar <span style="color:#e6db74">&#39;Mon..Fri *-*~01&#39;</span> <span style="color:#e6db74">&#39;Fri *-*~02..03&#39;</span> --iterations <span style="color:#ae81ff">10</span>
</span></span></code></pre></div><p>Optionally, filter and sort with the caveats from above:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>systemd-analyze calendar <span style="color:#e6db74">&#39;Mon..Fri *-*~01&#39;</span> <span style="color:#e6db74">&#39;Fri *-*~02..03&#39;</span> --iterations <span style="color:#ae81ff">10</span> <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    |grep Iteration |sort -k4
</span></span></code></pre></div>]]></content:encoded></item><item><title>Killing your Ceph with Autoscaling</title><link>https://www.relg.uk/posts/killing-your-ceph-with-autoscaling/</link><pubDate>Wed, 11 Jan 2023 22:42:15 +0100</pubDate><guid>https://www.relg.uk/posts/killing-your-ceph-with-autoscaling/</guid><description>&lt;p>I recently was consulted on a Ceph Cluster running into nearfull and backfillfull
for the first time. One Ceph OSD was utilized over 85% and another over 90%. The
operators were unaware of the meaning and what to do about it, so took a look.&lt;/p>
&lt;p>Looking at &lt;code>ceph status&lt;/code> and &lt;code>ceph df&lt;/code>, I noticed something. Try to spot it
yourself – I made it easier by removing some stuff around it:&lt;/p></description><content:encoded><![CDATA[<p>I recently was consulted on a Ceph Cluster running into nearfull and backfillfull
for the first time. One Ceph OSD was utilized over 85% and another over 90%. The
operators were unaware of the meaning and what to do about it, so took a look.</p>
<p>Looking at <code>ceph status</code> and <code>ceph df</code>, I noticed something. Try to spot it
yourself – I made it easier by removing some stuff around it:</p>
<pre tabindex="0"><code>$ ceph status
[...]
    health: HEALTH_WARN
            1 pools have many more objects per pg than average
            1 backfillfull osd(s)
            1 nearfull osd(s)
            Low space hindering backfill (add storage if this doesn&#39;t resolve itself): 1 pg backfill_toofull
            1 pgs not deep-scrubbed in time
            1 pgs not scrubbed in time
            20 pool(s) backfillfull

  services:
[...]
    osd: 96 osds: 96 up (since 4w), 96 in (since 12M); 1 remapped pgs
[...]
  data:
    volumes: 4/4 healthy
    pools:   20 pools, 4769 pgs
    objects: 31.90M objects, 117 TiB
    usage:   351 TiB used, 522 TiB / 873 TiB avail
    pgs:     299136/95689743 objects misplaced (0.313%)
             4763 active+clean
             5    active+clean+scrubbing+deep
             1    active+remapped+backfill_toofull
[...]
# ceph df
--- RAW STORAGE ---
CLASS     SIZE    AVAIL     USED  RAW USED  %RAW USED
hdd    873 TiB  522 TiB  351 TiB   351 TiB      40.19
TOTAL  873 TiB  522 TiB  351 TiB   351 TiB      40.19

--- POOLS ---
POOL                           ID   PGS   STORED  OBJECTS     USED  %USED  MAX AVAIL
device_health_metrics           1  4096  907 MiB      108  2.7 GiB      0     14 TiB
rbd                             4   145   97 TiB   25.39M  290 TiB  87.43     14 TiB
[...]
</code></pre><p>The raw usage was only at 40%. Why would one disk contain so much data? The
balancer was in upmap mode and active. But even with no balancer, this kind of
miss-balancing would be extreme and very unlikely.</p>
<p>You may have already spotted something odd in the Ceph Pool configuration. While
<code>device_health_metrics</code> contained less than 1GiB, it had 4096 PGs. At the same
time <code>rbd</code> contained 97TiB in just 145 PGs.</p>
<p>145 is not just no power of two (which would usually produce a Ceph Warning),
but also way to low for the about of data and Ceph OSD count.</p>
<h2 id="what-does-this-mean-for-storage-distribution">What Does This Mean for Storage Distribution?</h2>
<p>Estimating the size of one PG for pool <code>rbd</code> yields about 685GiB (97TiB/145).
How many (average sized) PGs will lead to utilization of one disk over 85%?</p>
<p>About 11.4 (85% * 9TiB / 685GiB)</p>
<p>Unfortunately, not every PG is the same size. Looking at the sizes, multiple PG
exceed 800GiB. Furthermore not every Ceph OSD receives the same amount of PGs.
And as we will soon see the number of PGs was trying to get lower.</p>
<h2 id="cause-and-distributing-data">Cause and Distributing Data</h2>
<p>But what actually caused the bogus PG numbers? The answer is: The PG Autoscaler.
For some reason only <code>device_health_metrics</code> set a <code>target_size_ratio</code> to 0.1.
This lead to the effective ratio to be 1 for this pool. Apparently the autoscaling
assumed this would mean all data would be stored in this pool. This also
explained why the number of PGs was not a power of two. The autoscaler set
<code>target_pg_num</code> to 32 to reduce the pool <code>rbd</code> even more. This was why there was
not Ceph Warning. This also means that if there were no disks were running full
right now, it certainly would have happened in the following days.</p>
<p>Before removing the ratio, I wanted to know what would happen. I disabled
autoscaling (<code>ceph osd pool set noautoscale</code>) and removed the target ratio:</p>
<pre tabindex="0"><code># ceph osd pool set device_health_metrics target_size_ratio 0
# ceph osd pool autoscale-status
POOL                             SIZE  TARGET SIZE  RATE  RAW CAPACITY   RATIO  TARGET RATIO  EFFECTIVE RATIO  BIAS  PG_NUM  NEW PG_NUM  AUTOSCALE  BULK
device_health_metrics          906.5M                3.0        873.1T  0.0000                                  1.0    4096           1  on         False
rbd                            99048G                3.0        873.1T  0.3323                                  1.0      32        1024  on         False
[...]
</code></pre><p>This was a lot better and we decided to re-enable autoscaling (<code>ceph osd pool unset noautoscale</code>) right away.</p>
<p>After a few minutes the backfillfull was gone. Soon to be followed by the
nearfull. After a few days of rebalancing both pools had the proper PG count.</p>
<p>I am not sure why the ratio was set and why it was interpreted as it was. The
<a href="https://docs.ceph.com/en/latest/rados/operations/placement-groups/#viewing-pg-scaling-recommendations">docs</a>
suggest this would not be a problem and I could not reproduce the behavior in a
more recent version of Ceph. So this was potentially fixed already.</p>
]]></content:encoded></item><item><title>Silent Synology</title><link>https://www.relg.uk/posts/silent-synology/</link><pubDate>Mon, 25 Apr 2022 01:03:22 +0200</pubDate><guid>https://www.relg.uk/posts/silent-synology/</guid><description>&lt;p>I recently revived my Synology D415+ NAS from &lt;a href="https://www.youtube.com/watch?v=PkZ0249t7SI&amp;amp;t=339s">silicon death&lt;/a> and it looks like
it works fine again. When I bought it, I wanted to be able to run any docker
image. Which is why I opted for Atom instead of ARM. Which is also why I upgraded
RAM to 8GB. The disks basically never spun down which made it quite noisy.
Now, I just want it to be silent, if not in use.&lt;/p></description><content:encoded><![CDATA[<p>I recently revived my Synology D415+ NAS from <a href="https://www.youtube.com/watch?v=PkZ0249t7SI&amp;t=339s">silicon death</a> and it looks like
it works fine again. When I bought it, I wanted to be able to run any docker
image. Which is why I opted for Atom instead of ARM. Which is also why I upgraded
RAM to 8GB. The disks basically never spun down which made it quite noisy.
Now, I just want it to be silent, if not in use.</p>
<p>I initially thought I could replace the DiskStation Manager (DSM) with a proper
Linux but from what I gathered, it is &ldquo;<a href="https://superuser.com/a/1569056">not doable without deeper knowledge</a>&rdquo;.</p>
<h2 id="adjusting-fans">Adjusting Fans</h2>
<p>I only inserted the first SSD so far and installed DSM 7.0 on it. The only
audible sound was the fans spinning and I found a <a href="https://return2.net/how-to-make-synology-diskstation-fans-quieter/">guide</a> to use a custom fan
profile to turn them off completely for low loads.</p>
<p>Step one: Set &ldquo;Fan Speed Mode&rdquo; to &ldquo;Quiet mode&rdquo; via the GUI in &ldquo;Hardware &amp;
Power&rdquo;. This can also be done by setting</p>
<p>Step two: Turning off fan check to allow for 0 speed operations.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span># cat /usr/local/etc/rc.d/fan_check_disable.sh &lt;&lt;EOF
</span></span><span style="display:flex;"><span>#!/bin/sh
</span></span><span style="display:flex;"><span>echo 0 &gt; /sys/module/avoton_synobios/parameters/check_fan
</span></span><span style="display:flex;"><span>EOF
</span></span><span style="display:flex;"><span># chmod <span style="color:#ae81ff">755</span> /usr/local/etc/rc.d/fan_check_disable.sh
</span></span></code></pre></div><p>Step three: Backup <code>/usr/syno/etc.defaults/scemd.xml</code> and <code>usr/syno/etc/scemd.xml</code>
Step four: Adjust fan profile as described in the <a href="https://return2.net/how-to-make-synology-diskstation-fans-quieter/">guide</a> with some modifications
in <code>/usr/syno/etc.defaults/scemd.xml</code> and <code>usr/syno/etc/scemd.xml</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-diff" data-lang="diff"><span style="display:flex;"><span><span style="color:#f92672">--- /usr/syno/etc/scemd.xml_2022-04-23	2021-10-18 15:26:05.000000000 +0200
</span></span></span><span style="display:flex;"><span><span style="color:#f92672"></span><span style="color:#a6e22e">+++ /usr/syno/etc/scemd.xml	2022-04-23 01:12:07.740595553 +0200
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e"></span><span style="color:#75715e">@@ -14,17 +14,21 @@
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span> 		&lt;cpu_temperature fan_speed=&#34;99%40hz&#34; action=&#34;SHUTDOWN&#34;&gt;95&lt;/cpu_temperature&gt;
</span></span><span style="display:flex;"><span> 	&lt;/fan_config&gt;
</span></span><span style="display:flex;"><span> 	&lt;fan_config period=&#34;20&#34; threshold=&#34;6&#34; type=&#34;DUAL_MODE_LOW&#34; hibernation_speed=&#34;UNKNOWN&#34;&gt;
</span></span><span style="display:flex;"><span><span style="color:#f92672">-		&lt;disk_temperature fan_speed=&#34;21%40hz&#34; action=&#34;NONE&#34;&gt;0&lt;/disk_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#f92672">-		&lt;disk_temperature fan_speed=&#34;35%40hz&#34; action=&#34;NONE&#34;&gt;42&lt;/disk_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#f92672">-		&lt;disk_temperature fan_speed=&#34;50%40hz&#34; action=&#34;NONE&#34;&gt;46&lt;/disk_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#f92672">-		&lt;disk_temperature fan_speed=&#34;70%40hz&#34; action=&#34;NONE&#34;&gt;53&lt;/disk_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#f92672"></span><span style="color:#a6e22e">+		&lt;disk_temperature fan_speed=&#34;01%40hz&#34; action=&#34;NONE&#34;&gt;0&lt;/disk_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+		&lt;disk_temperature fan_speed=&#34;10%40hz&#34; action=&#34;NONE&#34;&gt;41&lt;/disk_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+		&lt;disk_temperature fan_speed=&#34;20%40hz&#34; action=&#34;NONE&#34;&gt;46&lt;/disk_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+		&lt;disk_temperature fan_speed=&#34;35%40hz&#34; action=&#34;NONE&#34;&gt;48&lt;/disk_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+		&lt;disk_temperature fan_speed=&#34;50%40hz&#34; action=&#34;NONE&#34;&gt;50&lt;/disk_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+		&lt;disk_temperature fan_speed=&#34;70%40hz&#34; action=&#34;NONE&#34;&gt;54&lt;/disk_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e"></span> 		&lt;disk_temperature fan_speed=&#34;99%40hz&#34; action=&#34;NONE&#34;&gt;58&lt;/disk_temperature&gt;
</span></span><span style="display:flex;"><span> 		&lt;disk_temperature fan_speed=&#34;99%40hz&#34; action=&#34;SHUTDOWN&#34;&gt;61&lt;/disk_temperature&gt;
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span><span style="color:#f92672">-		&lt;cpu_temperature fan_speed=&#34;21%40hz&#34; action=&#34;NONE&#34;&gt;0&lt;/cpu_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#f92672">-		&lt;cpu_temperature fan_speed=&#34;50%40hz&#34; action=&#34;NONE&#34;&gt;50&lt;/cpu_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#f92672">-		&lt;cpu_temperature fan_speed=&#34;99%40hz&#34; action=&#34;NONE&#34;&gt;85&lt;/cpu_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#f92672">-		&lt;cpu_temperature fan_speed=&#34;99%40hz&#34; action=&#34;SHUTDOWN&#34;&gt;95&lt;/cpu_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#f92672"></span><span style="color:#a6e22e">+		&lt;cpu_temperature fan_speed=&#34;01%40hz&#34; action=&#34;NONE&#34;&gt;0&lt;/cpu_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+		&lt;cpu_temperature fan_speed=&#34;10%40hz&#34; action=&#34;NONE&#34;&gt;57&lt;/cpu_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+		&lt;cpu_temperature fan_speed=&#34;20%40hz&#34; action=&#34;NONE&#34;&gt;62&lt;/cpu_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+		&lt;cpu_temperature fan_speed=&#34;50%40hz&#34; action=&#34;NONE&#34;&gt;65&lt;/cpu_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+		&lt;cpu_temperature fan_speed=&#34;99%40hz&#34; action=&#34;NONE&#34;&gt;80&lt;/cpu_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e">+		&lt;cpu_temperature fan_speed=&#34;99%40hz&#34; action=&#34;SHUTDOWN&#34;&gt;90&lt;/cpu_temperature&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#a6e22e"></span> 	&lt;/fan_config&gt;
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span> &lt;fan_config hw_version=&#34;Synology-DX5&#34; period=&#34;20&#34; threshold=&#34;6&#34; type=&#34;DUAL_MODE_HIGH_EBOX&#34; hibernation_speed=&#34;FULL&#34;&gt;
</span></span></code></pre></div><p>Step five: Reboot NAS</p>
<h2 id="adding-disks">Adding Disks</h2>
<p>If you checked out the source for the fan profile, you might have noticed that I
skipped something more obvious. The IronWolf drives I bought are really loud
when spun up – louder than the stock fan configuration in fact. For quiet
operation they need to spin down when idle.</p>
<p>Looking at the md configuration I noticed something odd.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span># cat /proc/mdstat
</span></span><span style="display:flex;"><span>Personalities : [raid1]
</span></span><span style="display:flex;"><span>md2 : active raid1 sda3[0]
</span></span><span style="display:flex;"><span>      239376512 blocks super 1.2 [1/1] [U]
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>md1 : active raid1 sda2[0]
</span></span><span style="display:flex;"><span>      2097088 blocks [4/1] [U___]
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>md0 : active raid1 sda1[0]
</span></span><span style="display:flex;"><span>      2490176 blocks [4/1] [U___]
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>unused devices: &lt;none&gt;
</span></span></code></pre></div><p>The first SSD (<code>sda</code>) I inserted was split into 3 partitions and turned into 3
arrays. <code>md2</code> was the main bulk and what will is volume1. It is not mounted
directly to <code>/volume1</code> tough, but through <code>/dev/mapper/cachedev_0</code>. I assume
this is to enable adding a caching device later (which makes no sense in this
case) to be more flexible.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span># df -h /volume1/
</span></span><span style="display:flex;"><span>Filesystem              Size  Used Avail Use% Mounted on
</span></span><span style="display:flex;"><span>/dev/mapper/cachedev_0  220G   92G  101G  48% /volume1
</span></span><span style="display:flex;"><span># ls -l /dev/mapper/cachedev_0 /dev/md2
</span></span><span style="display:flex;"><span>brw------- 1 root root 253, 0 Apr 23 11:58 /dev/mapper/cachedev_0
</span></span><span style="display:flex;"><span>brw------- 1 root root   9, 2 Apr 23 11:58 /dev/md2
</span></span><span style="display:flex;"><span># dmsetup ls --tree <span style="color:#75715e">#  ^^^^^^ notice major and minor device numbers match up</span>
</span></span><span style="display:flex;"><span>cachedev_0 (253:0)
</span></span><span style="display:flex;"><span> └─ (9:2)
</span></span></code></pre></div><p><code>md0</code>(<code>sda1</code>) is used for <code>/</code> while I could not exactly figure out what
<code>md1</code>(<code>sda2</code>) was used for – I read it was swap somewhere but I could not verify
that, so don&rsquo;t quote me on that.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span># df -h /
</span></span><span style="display:flex;"><span>Filesystem      Size  Used Avail Use% Mounted on
</span></span><span style="display:flex;"><span>/dev/md0        2.3G  1.2G  1.1G  52% /
</span></span></code></pre></div><p>Notice <code>[U___]</code> on both <code>md0</code> and <code>md1</code> and what happens after I insert a second
SSD and configure it as Storage Pool 2 (no volume) via the GUI.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span># cat /proc/mdstat
</span></span><span style="display:flex;"><span>Personalities : [raid1]
</span></span><span style="display:flex;"><span>md3 : active raid1 sdb3[0]
</span></span><span style="display:flex;"><span>      120212800 blocks super 1.2 [1/1] [U]
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>md2 : active raid1 sda3[0]
</span></span><span style="display:flex;"><span>      239376512 blocks super 1.2 [1/1] [U]
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>md1 : active raid1 sdb2[4] sda2[0]
</span></span><span style="display:flex;"><span>      2097088 blocks [4/1] [U___]
</span></span><span style="display:flex;"><span>      [=======&gt;.............]  recovery = 37.0% (776576/2097088) finish=0.5min speed=36979K/sec
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>md0 : active raid1 sdb1[4] sda1[0]
</span></span><span style="display:flex;"><span>      2490176 blocks [4/1] [U___]
</span></span><span style="display:flex;"><span>      [=====&gt;...............]  recovery = 28.7% (716928/2490176) finish=0.9min speed=32587K/sec
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>unused devices: &lt;none&gt;
</span></span><span style="display:flex;"><span># cat /proc/mdstat
</span></span><span style="display:flex;"><span>Personalities : [raid1]
</span></span><span style="display:flex;"><span>md3 : active raid1 sdb3[0]
</span></span><span style="display:flex;"><span>      120212800 blocks super 1.2 [1/1] [U]
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>md2 : active raid1 sda3[0]
</span></span><span style="display:flex;"><span>      239376512 blocks super 1.2 [1/1] [U]
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>md1 : active raid1 sdb2[1] sda2[0]
</span></span><span style="display:flex;"><span>      2097088 blocks [4/2] [UU__]
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>md0 : active raid1 sdb1[1] sda1[0]
</span></span><span style="display:flex;"><span>      2490176 blocks [4/2] [UU__]
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>unused devices: &lt;none&gt;
</span></span></code></pre></div><p>Initializing the new disk resulted in it being split into three partitions as
well. It added the first two partitions to the RAID1 arrays <code>md0</code> and <code>md1</code> and
left the third partition for usage. This is kind of clever. After the initial
array sync – took a few seconds –, I could now remove the first SSD, if I wanted
without losing my operating system. I would still lose everything I installed on
the volume from this disk though. Indeed, this happens to every disk I insert and
initialize a storage pool on.</p>
<p>I inserted my 2 10T HDDs now, and indeed they undergo the same procedure. The
array sync took about 1-2 minutes this time and I ended up with <code>md4</code> and 2 more
members for <code>md0</code> and <code>md1</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span># cat /proc/mdstat
</span></span><span style="display:flex;"><span>Personalities : [raid1]
</span></span><span style="display:flex;"><span>md4 : active raid1 sdd3[1] sdc3[0]
</span></span><span style="display:flex;"><span>      9761614848 blocks super 1.2 [2/2] [UU]
</span></span><span style="display:flex;"><span>[...]
</span></span><span style="display:flex;"><span>md1 : active raid1 sdd2[3] sdc2[2] sdb2[1] sda2[0]
</span></span><span style="display:flex;"><span>      2097088 blocks [4/4] [UUUU]
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">
</span></span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010"></span>md0 : active raid1 sdd1[3] sdc1[2] sdb1[1] sda1[0]
</span></span><span style="display:flex;"><span>      2490176 blocks [4/4] [UUUU]
</span></span><span style="display:flex;"><span>[...]
</span></span></code></pre></div><p>This is great for simplicity and redundancy. I can yank any 3 disks and my
system keeps running. But what if anything is read or written to the system
disk? I expect this to hinder hibernation and spin down quite a bit.</p>
<h2 id="debugging-hdd-hibernation-part-1">Debugging HDD Hibernation Part 1</h2>
<p>I found the tool <code>/usr/syno/sbin/syno_hibernation_debug</code> to analyse hibernation
fails (<code>1</code> for &ldquo;Cannot Enter Hibernation&rdquo; or <code>2</code> for &ldquo;Which Interrupt
Hibernation&rdquo;). The older one used in many forum posts was and no longer
available (<code>syno_hibernate_debug_tool --enable 1</code>)</p>
<p>I enabled the debug log by <a href="https://www.synology-forum.de/threads/dsm6-syno_hibernation_debug.85792/">setting some options</a> in <code>/etc/synoinfo.conf</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ini" data-lang="ini"><span style="display:flex;"><span><span style="color:#a6e22e">enable_hibernation_debug</span><span style="color:#f92672">=</span><span style="color:#e6db74">&#34;yes&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">hibernation_debug_level</span><span style="color:#f92672">=</span><span style="color:#e6db74">&#34;1&#34;</span>
</span></span></code></pre></div><p>I tailed <code>/var/log/hibernationFull.log</code> to get a feel what happens. I stopped
the <code>tail</code> after I realised that reading a file from the disk I want to see idle
might not work very well.</p>
<p>After about 600 seconds the disks spun down only to spin up again 30 seconds later.
I looked at the hibernation log to see what had happened.</p>
<pre tabindex="0"><code>[Sat Apr 23 15:42:15 2022] ppid:1(systemd), pid:22779(syno_hibernatio), dirtied inode 20738 (hibernation.log) on md0
[Sat Apr 23 15:42:15 2022] ppid:1(systemd), pid:22779(syno_hibernatio), dirtied inode 20738 (hibernation.log) on md0
[Sat Apr 23 15:42:15 2022] ppid:1(systemd), pid:22779(syno_hibernatio), dirtied inode 20738 (hibernation.log) on md0
[Sat Apr 23 15:42:15 2022] ppid:1(systemd), pid:22779(syno_hibernatio), dirtied inode 30536 (hibernationFull.log) on md0
[Sat Apr 23 15:42:15 2022] ppid:1(systemd), pid:22779(syno_hibernatio), dirtied inode 30536 (hibernationFull.log) on md0
[Sat Apr 23 15:42:15 2022] ppid:1(systemd), pid:22779(syno_hibernatio), dirtied inode 30536 (hibernationFull.log) on md0
</code></pre><p>Huh, that&rsquo;s the pid for the <code>/usr/syno/sbin/syno_hibernation_debug</code> process. Did it wake itself up?</p>
<p>I looked deeper into to <code>syno_hibernation_debug</code> script to find out what was
going on. The script mainly took care of a few things:</p>
<ul>
<li>Reading configuration and running itself in the background if
<code>enable_hibernation_debug=&quot;yes&quot;</code> was found and <code>hibernation_debug_level</code> was
<code>1</code> or <code>2</code>.
<ul>
<li>If not, it killed the running debug process</li>
</ul>
</li>
<li><code>echo 1 &gt; /proc/sys/vm/block_dump</code> if enabled and <code>echo 0 &gt; /proc/sys/vm/block_dump</code> if not</li>
<li>it loops over <code>/sys/block/sd{a..d}/device/syno_idle_time</code> (in my case) to see
if the idle time was below the configured standby time</li>
<li>then it looks at <code>dmesg | tail -500</code></li>
<li>it also writes to two log files (this should be find, it calls <code>sync</code>
instantly afterwards and sleeps for 20s)</li>
</ul>
<p>This is when I gave up on the script. There really is nothing too special about
it that I cannot do by hand without waking the disks up by myself. But I still
have the feeling that internals might be at play that will always sync the array
at some point in time. I don&rsquo;t want the system to be on HDDs.</p>
<p>I tried again, this time by hand.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>echo <span style="color:#ae81ff">1</span> &gt; /proc/sys/vm/block_dump
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">while</span> sleep 1s; <span style="color:#66d9ef">do</span> cat /sys/block/sd<span style="color:#f92672">{</span>a..d<span style="color:#f92672">}</span>/device/syno_idle_time; echo; <span style="color:#66d9ef">done</span>
</span></span></code></pre></div><p>This time is was something else.</p>
<pre tabindex="0"><code>[Sat Apr 23 16:41:17 2022] ppid:1(systemd), pid:14381(scemd), dirtied inode 30475 (disk_overview.xml) on md0
[Sat Apr 23 16:41:17 2022] ppid:1(systemd), pid:14381(scemd), dirtied inode 30475 (disk_overview.xml) on md0
</code></pre><p>I wonder, if I missed this the first time, but <code>dmesg</code> does not go back far
enough and I am not willing to spend the time again. The other reason is that I
will definitely do something about the HDDs in the array. Simply ssh-ing to the
NAS wakes it up – reading <code>authorized_keys</code> or something? Probably more,
logging, etc.?</p>
<h2 id="removing-hdds-from-array">Removing HDDs from Array</h2>
<p>The fact that the idle times if all four disks (2xSSD, 2xHDD) were almost always
in sync to the same value, makes me sure that with this configuration it will be
very hard to achieve total silence with spin down or even debug it properly.</p>
<p>I removed the HDD partitions form arrays <code>md0</code> and <code>md1</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>mdadm /dev/md0 --fail /dev/sdc1
</span></span><span style="display:flex;"><span>mdadm /dev/md0 --remove /dev/sdc1
</span></span><span style="display:flex;"><span>mdadm /dev/md0 --fail /dev/sdd1
</span></span><span style="display:flex;"><span>mdadm /dev/md0 --remove /dev/sdd1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mdadm /dev/md1 --fail /dev/sdc2
</span></span><span style="display:flex;"><span>mdadm /dev/md1 --remove /dev/sdc2
</span></span><span style="display:flex;"><span>mdadm /dev/md1 --fail /dev/sdd2
</span></span><span style="display:flex;"><span>mdadm /dev/md1 --remove /dev/sdd2
</span></span></code></pre></div><p>Resulting in this (notice that I ):</p>
<pre tabindex="0"><code># cat /proc/mdstat
Personalities : [raid1]
md4 : active raid1 sdd3[1] sdc3[0]
      9761614848 blocks super 1.2 [2/2] [UU]
[...]
md1 : active raid1 sdb2[1] sda2[0]
      2097088 blocks [4/2] [UU__]

md0 : active raid1 sdb1[1] sda1[0]
      2490176 blocks [4/2] [UU__]
[...]
</code></pre><p>Synology did not like that.
<img alt="Drives 3 and 4 report System Partition Failed" loading="lazy" src="/posts/silent-synology/drives_system_partition_failed.png">
<strong>Important</strong>: Do <strong>not</strong> shrink the arrays. I did so at first (<code>mdadm /dev/md0 --grow -n 2</code>, same for <code>md1</code>) but when I later rebooted the machine, it went to
the setup wizard instead. Fixing this was easy: I shut down the NAS, removed the
HDDs and booted again. After it was done, I inserted the HDDs again, and
assembled the array again (can be done via GUI).</p>
<p><strong>Advice: Do not do this</strong> – unless you are sure of the consequences it might
have. I expect this to break with OS upgrades and the like. Same for fan
profiles.</p>
<p>I looked at idle times again and was pleased to see that ssh-ing to the machine
only reset idle times for the remaining SSDs in the system arrays.</p>
<p>Sadly that did not last long since the idle time rose above 10 minutes without
the disks spinning down. Did Synology stop tracking the disk for some reason?</p>
<p>Time to postpone for this day.</p>
<h2 id="debugging-hdd-hibernation-part-2">Debugging HDD Hibernation Part 2</h2>
<p>I noticed when the HDD did spin down, looking at
<code>/sys/block/sd{a..d}/device/syno_idle_time</code> took longer. So this does not count
as something to interrupt the idle time but it does wake up the disk. The
<code>syno_hibernation_debug</code> script basically only works for checking why a disk
does not enter hibernation but not for what wakes it up, because it will wake the
disk up itself. All debugging efforts basically lead to spin-up – the <a href="https://www.synology-wiki.de/index.php/Hibernation:_Dinge,_die_den_Disk-Spin-Down_betreffen#:~:text=Das%20Aktivieren%20des%20Logs%20kann%20den%20Hibernation%2DModus%20selbst%20ebenfalls%20beeintr%C3%A4chtigen.%20Es%20sollte%20daher%20nicht%20dauerhaft%20sondern%20nur%20zur%20Diagnose%20aktiviert%20werden!">German
wiki page on hibernation</a> even touches on something like this briefly.</p>
<p>New approach: I disabled all debugging measures (including hibernation log),
closed all ssh connections, closed the webinterface and check for open
connections to the machine (<code>lsof -i@$hostname_of_NAS</code>). Time for some series, a
10-15 minute timer and listening if the disks spin down at some point. I left
<code>echo 1 &gt; /proc/sys/vm/block_dump</code> to check for what woke up the drives if they
did.</p>
<h3 id="with-advanced-sleep">With Advanced Sleep</h3>
<p>After waiting about ten minutes the disks spun down and the yellow LEDs went off
(Status and disks) while the blue power LED stayed solid. The fans did not spin
up. (There was some network activity I saw on my router at a later date, mainly
ARP and NTP).</p>
<p>When I connected to the web GUI after over an hour the disks spun up and the LED
went back on. Looking at <code>dmesg</code> and searching for the HDDs I saw some activity
I assume to be a result of waking up from deep sleep and checking if anything
changed with the disks.</p>
<pre tabindex="0"><code>[Sun Apr 24 17:15:56 2022] sd 5:0:0:0: [sdd] Write cache: enabled, read cache: enabled, doesn&#39;t support DPO or FUA
[Sun Apr 24 17:16:01 2022] sd 4:0:0:0: [sdc] Write cache: disabled, read cache: enabled, doesn&#39;t support DPO or FUA
[Sun Apr 24 17:16:02 2022] sd 5:0:0:0: [sdd] Write cache: disabled, read cache: enabled, doesn&#39;t support DPO or FUA
[Sun Apr 24 17:16:26 2022] ppid:2(kthreadd), pid:30085(kworker/3:0), READ block 8 on sdd3 (8 sectors)
[Sun Apr 24 17:16:26 2022] ppid:2(kthreadd), pid:30085(kworker/3:0), READ block 8 on sdc3 (8 sectors)
[Sun Apr 24 17:16:26 2022] ppid:2(kthreadd), pid:6707(md4_raid1), WRITE block 8 on sdd3 (1 sectors)
[Sun Apr 24 17:16:26 2022] ppid:2(kthreadd), pid:6707(md4_raid1), WRITE block 8 on sdc3 (1 sectors)
[Sun Apr 24 17:16:26 2022] ppid:2(kthreadd), pid:6707(md4_raid1), WRITE block 8 on sdd3 (1 sectors)
[Sun Apr 24 17:16:26 2022] ppid:2(kthreadd), pid:6707(md4_raid1), WRITE block 8 on sdc3 (1 sectors)
</code></pre><p>I waited until the disk were silent again and the LEDs went off and connected
via ssh – again, disk spin.</p>
<pre tabindex="0"><code>[Sun Apr 24 17:29:55 2022] sd 4:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn&#39;t support DPO or FUA
</code></pre><h3 id="without-advanced-sleep">Without Advanced Sleep</h3>
<p>My hope was, by not going into deep sleep to not wake the HDDs from their
spin-down when connecting to the GUI or via ssh. After waiting 10 minutes the
disks spun down but all LEDs stayed on. About every 10 minutes the fans spun up
for 2-3 minutes but the disks stayed spun down. My guess would be that not going
into deeps sleep the CPU and maybe the SSDs needed more power wich lead to
higher temperature and thus a higher cooling need.</p>
<p>When I connected via ssh the HDDs spun up. There was nothing for the disks in
<code>dmesg</code> what had accessed the disks.</p>
<p>I waited for the disks to go silent again and tried the same with connecting via
the GUI. Unfortunately, the disks ramped up again.</p>
<pre tabindex="0"><code>[Sun Apr 24 18:42:59 2022] ppid:2(kthreadd), pid:30021(kworker/2:1), READ block 8 on sdb3 (8 sectors)
[Sun Apr 24 18:42:59 2022] ppid:2(kthreadd), pid:30021(kworker/2:1), READ block 8 on sda3 (8 sectors)
</code></pre><h2 id="hunting-ghosts">Hunting Ghosts</h2>
<p>This is where I put down my pen for now and talk about what I have learned on
this adventure.</p>
<p>I guess my initial assumption that the disks didn&rsquo;t properly spin down was
false. Maybe I had installed something that kept disks awake back then or didn&rsquo;t
properly configure hibernate. Either way, <strong>do not assume something is (still)
broken</strong>; verify before you invest time in debugging. For the mathematically
inclined, for a <a href="https://en.wikipedia.org/wiki/Mathematical_induction">complete induction</a> it is essential to prove the base case
before doing the induction step.</p>
<p><strong>Measuring has its costs</strong> or there ain&rsquo;t no such thing as a free lunch. When
looking at metrics, surveying the data will change the data from what it would
have been – reminds me of the <a href="https://en.wikipedia.org/wiki/Uncertainty_principle">uncertainty principle</a>, somehow.</p>
<h2 id="whats-next">What&rsquo;s next</h2>
<p>I will keep my weird RAID configuration (for now), in case it did help. I am
comfortable with dealing with potential fails that might occur.
I moved the HDDs to the slots away from the mainboard to reduce heat radiating
to them. I will keep the advanced/deep sleep configuration since there was no
observable benefit from disabling deep sleep, if ssh-ing would wake up the HDDs
anyways. I still do not understand this behavior and if anybody has an idea and
how to fix it, please let me know.</p>
<p>PS: I am aware that constantly spinning disks might not wear out as fast but
this is a risk I am willing to take right now.</p>
]]></content:encoded></item><item><title>Starting to Blog</title><link>https://www.relg.uk/posts/starting-to-blog/</link><pubDate>Fri, 17 Dec 2021 20:06:17 +0100</pubDate><guid>https://www.relg.uk/posts/starting-to-blog/</guid><description>&lt;p>Recently re-inspired to start to blog, I decided to open – same as
&lt;a href="https://jay.jvf.cc/posts/about-itself/">Jay Faulkner&lt;/a> – with a meta post about why, what to expect, and how I (will) do
it.&lt;/p>
&lt;h2 id="why-i-want-to-blog">Why I Want to Blog&lt;/h2>
&lt;p>If I start to learn a new topic, I feel like a total beginner. But the more I
learn about something, the more I can draw from related topics to generate a
more complete understanding of how it works. We all go through this. But
at which point is it okay to talk about it as if you were knowledgable about the
topic? I would say, do it earlier than you think, be honest about your state of
understanding, and do not be afraid to be wrong (as long as it does not kill
anyone). Writing is understanding.&lt;/p></description><content:encoded><![CDATA[<p>Recently re-inspired to start to blog, I decided to open – same as
<a href="https://jay.jvf.cc/posts/about-itself/">Jay Faulkner</a> – with a meta post about why, what to expect, and how I (will) do
it.</p>
<h2 id="why-i-want-to-blog">Why I Want to Blog</h2>
<p>If I start to learn a new topic, I feel like a total beginner. But the more I
learn about something, the more I can draw from related topics to generate a
more complete understanding of how it works. We all go through this. But
at which point is it okay to talk about it as if you were knowledgable about the
topic? I would say, do it earlier than you think, be honest about your state of
understanding, and do not be afraid to be wrong (as long as it does not kill
anyone). Writing is understanding.</p>
<p>When you write – or speak – about a topic several things happen. You are forced
to form complete sentences and express the idea as clear as you can. While you
do, you might discover that you are still missing pieces or that your current
understanding is wrong is some way. Another thing you might notice is, that you
are unsure, if it is correct. Again, do not be afraid to be wrong but take the
opportunity to learn more. Maybe there is another way to look at the concept
that might be easier to explain. Writing about topic or concept can be helpful
to someone reading it as well as writing about the learning experiences itself.
My hope is to write about topics where I am on the way up from the valley of
despair (Dunning–Kruger effect) or make the valley not as deep.
I currently only write into my personal notes – mainly for documentation and
findability. But it is too easy to just jot down bullet points and not actually
understanding what you have written. I hope blogging deepens my understanding of
things and also helps others understand the topic a little bit better.</p>
<h2 id="inspiration">Inspiration</h2>
<p>I read some other tech blogs like <a href="https://xahteiwi.eu/">Florian Haas</a>, <a href="https://michael.stapelberg.ch/">Michael Stapelberg</a>, and
<a href="https://blog.koehntopp.info/">Kristian Köhntopp</a>. I hugely respect all of them and enjoy their different
content. I also enjoy the content <a href="https://www.youtube.com/channel/UClcE-kVhqyiHCcjYwcpfj9w">liveoverflow</a> produces on YouTube.</p>
<h2 id="what-to-expect">What to Expect</h2>
<p>There is not set path for what you will find here in the future but I have some
rough ideas what topics to cover.
Subject to change but stuff I currently thing about:</p>
<ul>
<li>debugging issues and learning experiences</li>
<li>git, gnupg, gaming on Linux, i3, restic and systemd, scripts, vim, zsh</li>
<li><a href="https://obsidian.md/">Obsidian</a>: documentation, note taking</li>
<li>maybe opinions: remote work</li>
<li>eventually: slides to talks</li>
</ul>
<h2 id="how-i-blog">How I Blog</h2>
<p>Most importantly – since this is something new to me – irregular and
opportunistic. If I find something interesting enough, you will find it here.</p>
<p>On the technical side: The repo <a href="https://github.com/Syphdias/syphdias.github.io">syphdias.github.io</a> contains this page&rsquo;s
contents as markdown files and configuration files. <a href="https://docs.github.com/en/actions">GitHub Actions</a> are being
used to use <a href="https://github.com/gohugoio/hugo">hugo</a> with the theme <a href="https://github.com/adityatelange/hugo-PaperMod">PaperMod</a> to generate a static page on the
branch <code>gh-pages</code>. It is then hosted by <a href="https://docs.github.com/en/pages">GitHub Pages</a>.</p>
<p>There is a <a href="https://www.relg.uk/index.xml">RSS/Atom feed</a> you can use and I might enable comments if I am in
the mood.</p>
<p>If you find mistakes in any of my posts, feel free to contribute a pull request.</p>
]]></content:encoded></item></channel></rss>